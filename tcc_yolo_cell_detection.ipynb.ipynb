{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-25T00:13:35.920192Z",
     "iopub.status.busy": "2025-06-25T00:13:35.919680Z",
     "iopub.status.idle": "2025-06-25T00:14:50.642563Z",
     "shell.execute_reply": "2025-06-25T00:14:50.641829Z",
     "shell.execute_reply.started": "2025-06-25T00:13:35.920169Z"
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Setup Completo - Instalação e Imports\n",
    "# Execute esta célula primeiro sempre que reiniciar o kernel\n",
    "\n",
    "# 1. Instalação de Dependências\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_package(package_name, import_name=None):\n",
    "    \n",
    "    if import_name is None:\n",
    "        import_name = package_name\n",
    "    \n",
    "    try:\n",
    "        __import__(import_name)\n",
    "        print(f\"    {package_name} já instalado\")\n",
    "        return True\n",
    "    except ImportError:\n",
    "        print(f\"   Instalando {package_name}...\")\n",
    "        try:\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package_name, \"-q\"])\n",
    "            print(f\"   {package_name} instalado com sucesso\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"   Erro ao instalar {package_name}: {e}\")\n",
    "            return False\n",
    "\n",
    "\n",
    "# Lista de pacotes necessários\n",
    "packages_to_install = [\n",
    "    (\"ultralytics\", \"ultralytics\"),  # YOLO\n",
    "    (\"opencv-python\", \"cv2\"),        # OpenCV\n",
    "    (\"seaborn\", \"seaborn\"),         # Visualização\n",
    "    (\"scikit-learn\", \"sklearn\"),     # ML metrics\n",
    "    (\"pillow\", \"PIL\"),              # Processamento de imagens\n",
    "    (\"pyyaml\", \"yaml\"),             # YAML parsing\n",
    "]\n",
    "\n",
    "failed_installs = []\n",
    "for package, import_name in packages_to_install:\n",
    "    if not install_package(package, import_name):\n",
    "        failed_installs.append(package)\n",
    "\n",
    "# 2. Imports Principais\n",
    "\n",
    "# Bibliotecas do sistema\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Manipulação de dados e caminhos\n",
    "import json\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "# Computação científica\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualização\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns\n",
    "\n",
    "# Processamento de imagens\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "# Machine Learning\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    precision_recall_curve, \n",
    "    f1_score, \n",
    "    confusion_matrix, \n",
    "    classification_report, \n",
    "    roc_curve, \n",
    "    auc\n",
    ")  \n",
    "\n",
    "# YOLO (principal)\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# 3. Configuração do Ambiente\n",
    "\n",
    "# Suprimir warnings desnecessários\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configurar matplotlib\n",
    "plt.style.use('default')  # Mais compatível\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# Configurar seaborn\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Verificar GPU\n",
    "\n",
    "# PyTorch CUDA\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"    GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"    VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"   GPU: Não disponível (usando CPU)\")\n",
    "\n",
    "# Verificar versões importantes\n",
    "\n",
    "version_info = [\n",
    "    (\"Python\", sys.version.split()[0]),\n",
    "    (\"NumPy\", np.__version__),\n",
    "    (\"Pandas\", pd.__version__),\n",
    "    (\"PyTorch\", torch.__version__),\n",
    "    (\"OpenCV\", cv2.__version__),\n",
    "]\n",
    "\n",
    "import ultralytics\n",
    "version_info.append((\"Ultralytics\", ultralytics.__version__))\n",
    "\n",
    "for lib, version in version_info:\n",
    "    print(f\"   • {lib}: {version}\")\n",
    "\n",
    "# 4. Configurações Específicas\n",
    "\n",
    "# Configurações de reprodutibilidade\n",
    "def set_seeds(seed=42):\n",
    "   \n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    # Para determinismo no YOLO (quando possível)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "set_seeds(42)\n",
    "\n",
    "# Classes do projeto\n",
    "CLASS_NAMES = ['COM_corante', 'SEM_corante']\n",
    "CLASS_COLORS = {'COM_corante': 'blue', 'SEM_corante': 'red'}\n",
    "\n",
    "# Paths comuns\n",
    "COMMON_PATHS = {\n",
    "    'dataset': '/kaggle/working/yolo_dataset',\n",
    "    'models': '/kaggle/working/yolo_training', \n",
    "    'optimization': '/kaggle/working/yolo_optimization',\n",
    "    'output': '/kaggle/working'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-25T00:15:00.092322Z",
     "iopub.status.busy": "2025-06-25T00:15:00.091923Z",
     "iopub.status.idle": "2025-06-25T00:15:00.293952Z",
     "shell.execute_reply": "2025-06-25T00:15:00.293338Z",
     "shell.execute_reply.started": "2025-06-25T00:15:00.092302Z"
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Bloco 1: Setup e Análise Exploratória dos Dados\n",
    "# Pipeline: YOLO (Detecção e Classificação)\n",
    "\n",
    "# Configuração de visualização\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "\n",
    "print(\" Bloco 1: Setup e Análise Exploratória\")\n",
    "print(\" Pipeline: YOLO (Detecção e Classificação)\")\n",
    "\n",
    "\n",
    "# 1. Configuração de Paths e Constantes\n",
    "\n",
    "# IMPORTANTE: Ajustar estes paths conforme dataset\n",
    "BASE_PATH = \"/kaggle/input/dataset2-tcc/DatasetV2\"\n",
    "\n",
    "PATHS = {\n",
    "    'train': {\n",
    "        'json': f\"{BASE_PATH}/train/_annotations.coco.json\",\n",
    "        'images': f\"{BASE_PATH}/train/\"\n",
    "    },\n",
    "    'valid': {\n",
    "        'json': f\"{BASE_PATH}/valid/_annotations.coco.json\", \n",
    "        'images': f\"{BASE_PATH}/valid/\"\n",
    "    },\n",
    "    'test': {\n",
    "        'json': f\"{BASE_PATH}/test/_annotations.coco.json\",\n",
    "        'images': f\"{BASE_PATH}/test/\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Mapeamento de Classes: 4 originais → 2 binárias\n",
    "CLASS_MAPPING = {\n",
    "    'blue cell': 'COM_corante',\n",
    "    'grumo azul': 'COM_corante', \n",
    "    'normal cell': 'SEM_corante',\n",
    "    'grumo normal': 'SEM_corante',\n",
    "    'corante': None,  # ignorar\n",
    "    'cells': None     # ignorar\n",
    "}\n",
    "\n",
    "# Classes finais para classificação\n",
    "BINARY_CLASSES = ['COM_corante', 'SEM_corante']\n",
    "\n",
    "print(f\" Dataset path configurado: {BASE_PATH}\")\n",
    "print(f\" Mapeamento binário: {len(BINARY_CLASSES)} classes\")\n",
    "print(f\"   • COM_corante: blue cell + grumo azul\")\n",
    "print(f\"   • SEM_corante: normal cell + grumo normal\")\n",
    "\n",
    "# 2. FUNÇÕES AUXILIARES\n",
    "\n",
    "def load_coco_annotations(json_path):\n",
    "   \n",
    "    \n",
    "    with open(json_path, 'r') as f:\n",
    "        coco_data = json.load(f)\n",
    "    \n",
    "    # Extrair informações\n",
    "    images = {img['id']: img for img in coco_data['images']}\n",
    "    categories = {cat['id']: cat['name'] for cat in coco_data['categories']}\n",
    "    annotations = coco_data['annotations']\n",
    "    \n",
    "    print(f\" Carregado: {len(images)} imagens, {len(annotations)} anotações\")\n",
    "    \n",
    "    return coco_data, images, categories, annotations        \n",
    "    \n",
    "\n",
    "def extract_annotation_stats(annotations, categories, class_mapping):\n",
    "    \n",
    "    stats = {\n",
    "        'original_classes': defaultdict(int),\n",
    "        'binary_classes': defaultdict(int),\n",
    "        'bbox_sizes': [],\n",
    "        'ignored_classes': defaultdict(int)\n",
    "    }\n",
    "    \n",
    "    valid_annotations = []\n",
    "    \n",
    "    for ann in annotations:\n",
    "        # Classe original\n",
    "        class_id = ann['category_id']\n",
    "        class_name = categories[class_id]\n",
    "        stats['original_classes'][class_name] += 1\n",
    "        \n",
    "        # Mapeamento binário\n",
    "        binary_class = class_mapping.get(class_name)\n",
    "        \n",
    "        if binary_class is not None:\n",
    "            stats['binary_classes'][binary_class] += 1\n",
    "            \n",
    "            # Estatísticas da bounding box\n",
    "            bbox = ann['bbox']  # [x, y, width, height]\n",
    "            area = bbox[2] * bbox[3]\n",
    "            stats['bbox_sizes'].append({\n",
    "                'width': bbox[2],\n",
    "                'height': bbox[3], \n",
    "                'area': area,\n",
    "                'class': binary_class\n",
    "            })\n",
    "            \n",
    "            valid_annotations.append({\n",
    "                'annotation_id': ann['id'],\n",
    "                'image_id': ann['image_id'],\n",
    "                'bbox': bbox,\n",
    "                'area': area,\n",
    "                'original_class': class_name,\n",
    "                'binary_class': binary_class\n",
    "            })\n",
    "        else:\n",
    "            stats['ignored_classes'][class_name] += 1\n",
    "    \n",
    "    return stats, valid_annotations\n",
    "\n",
    "def visualize_class_distribution(stats, split_name):\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    \n",
    "    # 1. Classes originais\n",
    "    orig_classes = list(stats['original_classes'].keys())\n",
    "    orig_counts = list(stats['original_classes'].values())\n",
    "    \n",
    "    axes[0].bar(orig_classes, orig_counts, alpha=0.7)\n",
    "    axes[0].set_title(f'{split_name} - Classes Originais')\n",
    "    axes[0].set_ylabel('Número de Anotações')\n",
    "    axes[0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # 2. Classes binárias\n",
    "    binary_classes = list(stats['binary_classes'].keys())\n",
    "    binary_counts = list(stats['binary_classes'].values())\n",
    "    \n",
    "    colors = ['skyblue', 'lightcoral']\n",
    "    axes[1].bar(binary_classes, binary_counts, color=colors, alpha=0.7)\n",
    "    axes[1].set_title(f'{split_name} - Classes Binárias (Final)')\n",
    "    axes[1].set_ylabel('Número de Anotações')\n",
    "    \n",
    "    # Adicionar percentuais\n",
    "    total = sum(binary_counts)\n",
    "    for i, (cls, count) in enumerate(zip(binary_classes, binary_counts)):\n",
    "        pct = (count/total)*100\n",
    "        axes[1].text(i, count + max(binary_counts)*0.01, \n",
    "                    f'{count}\\n({pct:.1f}%)', \n",
    "                    ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # 3. Classes ignoradas (se houver)\n",
    "    if stats['ignored_classes']:\n",
    "        ign_classes = list(stats['ignored_classes'].keys())\n",
    "        ign_counts = list(stats['ignored_classes'].values())\n",
    "        \n",
    "        axes[2].bar(ign_classes, ign_counts, color='gray', alpha=0.7)\n",
    "        axes[2].set_title(f'{split_name} - Classes Ignoradas')\n",
    "        axes[2].set_ylabel('Número de Anotações')\n",
    "        axes[2].tick_params(axis='x', rotation=45)\n",
    "    else:\n",
    "        axes[2].text(0.5, 0.5, 'Nenhuma classe\\nfoi ignorada', \n",
    "                    ha='center', va='center', transform=axes[2].transAxes,\n",
    "                    fontsize=12, alpha=0.6)\n",
    "        axes[2].set_title(f'{split_name} - Classes Ignoradas')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def analyze_bbox_sizes(bbox_data):\n",
    "    \n",
    "    df = pd.DataFrame(bbox_data)\n",
    "    \n",
    "    print(f\"\\n Análise de Bounding Boxes:\")    \n",
    "    \n",
    "    # Estatísticas gerais\n",
    "    print(f\"Total de bounding boxes válidas: {len(df)}\")\n",
    "    print(f\"\\nEstatísticas de tamanho:\")\n",
    "    print(f\"Width  - Min: {df['width'].min():.1f}, Max: {df['width'].max():.1f}, Média: {df['width'].mean():.1f}\")\n",
    "    print(f\"Height - Min: {df['height'].min():.1f}, Max: {df['height'].max():.1f}, Média: {df['height'].mean():.1f}\")\n",
    "    print(f\"Area   - Min: {df['area'].min():.1f}, Max: {df['area'].max():.1f}, Média: {df['area'].mean():.1f}\")\n",
    "    \n",
    "    # Por classe\n",
    "    print(f\"\\nPor classe:\")\n",
    "    for cls in df['class'].unique():\n",
    "        subset = df[df['class'] == cls]\n",
    "        print(f\"  {cls}:\")\n",
    "        print(f\"    Width média: {subset['width'].mean():.1f} ± {subset['width'].std():.1f}\")\n",
    "        print(f\"    Height média: {subset['height'].mean():.1f} ± {subset['height'].std():.1f}\")\n",
    "        print(f\"    Area média: {subset['area'].mean():.1f} ± {subset['area'].std():.1f}\")\n",
    "    \n",
    "    # Visualização\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Distribuição de larguras\n",
    "    for cls in df['class'].unique():\n",
    "        subset = df[df['class'] == cls]\n",
    "        axes[0,0].hist(subset['width'], alpha=0.6, label=cls, bins=20)\n",
    "    axes[0,0].set_title('Distribuição de Larguras')\n",
    "    axes[0,0].set_xlabel('Width (pixels)')\n",
    "    axes[0,0].legend()\n",
    "    \n",
    "    # Distribuição de alturas\n",
    "    for cls in df['class'].unique():\n",
    "        subset = df[df['class'] == cls]\n",
    "        axes[0,1].hist(subset['height'], alpha=0.6, label=cls, bins=20)\n",
    "    axes[0,1].set_title('Distribuição de Alturas')\n",
    "    axes[0,1].set_xlabel('Height (pixels)')\n",
    "    axes[0,1].legend()\n",
    "    \n",
    "    # Scatter width vs height\n",
    "    colors = {'COM_corante': 'blue', 'SEM_corante': 'red'}\n",
    "    for cls in df['class'].unique():\n",
    "        subset = df[df['class'] == cls]\n",
    "        axes[1,0].scatter(subset['width'], subset['height'], \n",
    "                         alpha=0.6, label=cls, color=colors.get(cls, 'gray'))\n",
    "    axes[1,0].set_title('Width vs Height')\n",
    "    axes[1,0].set_xlabel('Width (pixels)')\n",
    "    axes[1,0].set_ylabel('Height (pixels)')\n",
    "    axes[1,0].legend()\n",
    "    \n",
    "    # Distribuição de áreas (log scale)\n",
    "    for cls in df['class'].unique():\n",
    "        subset = df[df['class'] == cls]\n",
    "        axes[1,1].hist(np.log10(subset['area']), alpha=0.6, label=cls, bins=20)\n",
    "    axes[1,1].set_title('Distribuição de Áreas (log10)')\n",
    "    axes[1,1].set_xlabel('log10(Area)')\n",
    "    axes[1,1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return df\n",
    "\n",
    "# 3. Carregamento e Análise dos Dados\n",
    "\n",
    "print(f\"\\n Carregando Dados dos 3 Splits...\")\n",
    "\n",
    "all_stats = {}\n",
    "all_annotations = {}\n",
    "\n",
    "for split_name, paths in PATHS.items():\n",
    "    print(f\"\\n Processando split: {split_name.upper()}\")    \n",
    "    \n",
    "    # Carregar anotações COCO\n",
    "    coco_data, images, categories, annotations = load_coco_annotations(paths['json'])    \n",
    "        \n",
    "    # Extrair estatísticas\n",
    "    stats, valid_annotations = extract_annotation_stats(annotations, categories, CLASS_MAPPING)\n",
    "    \n",
    "    # Armazenar\n",
    "    all_stats[split_name] = stats\n",
    "    all_annotations[split_name] = valid_annotations\n",
    "    \n",
    "    print(f\" Resumo do {split_name}:\")\n",
    "    print(f\"   • Total de imagens: {len(images)}\")\n",
    "    print(f\"   • Total de anotações: {len(annotations)}\")\n",
    "    print(f\"   • Anotações válidas: {len(valid_annotations)}\")\n",
    "    \n",
    "    # Classes binárias\n",
    "    for cls, count in stats['binary_classes'].items():\n",
    "        total_binary = sum(stats['binary_classes'].values())\n",
    "        pct = (count/total_binary)*100\n",
    "        print(f\"   • {cls}: {count} ({pct:.1f}%)\")\n",
    "    \n",
    "    # Classes ignoradas\n",
    "    if stats['ignored_classes']:\n",
    "        print(f\"   • Classes ignoradas: {dict(stats['ignored_classes'])}\")\n",
    "\n",
    "# 4. Análise Consolidada\n",
    "\n",
    "print(f\"\\n Análise dos Dados\")\n",
    "\n",
    "# Consolidar estatísticas\n",
    "total_stats = {\n",
    "    'images': 0,\n",
    "    'annotations': 0,\n",
    "    'valid_annotations': 0,\n",
    "    'binary_classes': defaultdict(int)\n",
    "}\n",
    "\n",
    "for split_name, stats in all_stats.items():\n",
    "    total_stats['valid_annotations'] += len(all_annotations[split_name])\n",
    "    for cls, count in stats['binary_classes'].items():\n",
    "        total_stats['binary_classes'][cls] += count\n",
    "\n",
    "print(f\" Dataset Completo:\")\n",
    "print(f\"   • Total de anotações válidas: {total_stats['valid_annotations']}\")\n",
    "\n",
    "total_binary = sum(total_stats['binary_classes'].values())\n",
    "for cls, count in total_stats['binary_classes'].items():\n",
    "    pct = (count/total_binary)*100\n",
    "    print(f\"   • {cls}: {count} ({pct:.1f}%)\")\n",
    "\n",
    "# Verificar balanceamento\n",
    "com_pct = (total_stats['binary_classes']['COM_corante']/total_binary)*100\n",
    "sem_pct = (total_stats['binary_classes']['SEM_corante']/total_binary)*100\n",
    "balance_ratio = min(com_pct, sem_pct) / max(com_pct, sem_pct)\n",
    "\n",
    "print(f\"\\n  Análise de Balanceamento:\")\n",
    "print(f\"   • COM_corante: {com_pct:.1f}%\")\n",
    "print(f\"   • SEM_corante: {sem_pct:.1f}%\")\n",
    "print(f\"   • Ratio de balanceamento: {balance_ratio:.3f}\")\n",
    "\n",
    "print(f\"\\n Bloco 1 Carregado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-25T00:15:35.665943Z",
     "iopub.status.busy": "2025-06-25T00:15:35.665619Z",
     "iopub.status.idle": "2025-06-25T00:15:49.582643Z",
     "shell.execute_reply": "2025-06-25T00:15:49.582069Z",
     "shell.execute_reply.started": "2025-06-25T00:15:35.665922Z"
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Bloco 2 : Preparação dos Dados\n",
    "# Pipeline: YOLO (Detecção e Classificação)\n",
    "\n",
    "print(\" Bloco 2: Preparação dos Dados\")\n",
    "print(\" Objetivos: Análise + Visualização + Conversão + Extração\")\n",
    "\n",
    "# 1. Configurações e Parâmetros\n",
    "\n",
    "# Parâmetros para extração de patches\n",
    "PATCH_SIZE = 224  # Padrão para transfer learning\n",
    "OUTPUT_BASE = \"/kaggle/working\"  # Diretório de saída no Kaggle\n",
    "\n",
    "# Mapeamento de classes para YOLO (0, 1)\n",
    "CLASS_MAPPING_REVERSE = {\n",
    "    'COM_corante': 0,\n",
    "    'SEM_corante': 1\n",
    "}\n",
    "\n",
    "CLASS_NAMES = ['COM_corante', 'SEM_corante']\n",
    "\n",
    "print(f\"\\n Configuração Inicial:\")\n",
    "print(f\"   • Tamanho do patch: {PATCH_SIZE}x{PATCH_SIZE}\")\n",
    "print(f\"   • Classes YOLO: {CLASS_NAMES}\")\n",
    "print(f\"   • Diretório de saída: {OUTPUT_BASE}\")\n",
    "\n",
    "# 2. Funções Utilitárias\n",
    "\n",
    "def load_image_safely(image_path):    \n",
    "    \n",
    "    if os.path.exists(image_path):\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is not None:\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            return image\n",
    "    print(f\" Imagem não encontrada: {image_path}\")\n",
    "    return None\n",
    "\n",
    "def create_directories():\n",
    "    \n",
    "    print(f\"\\n Criando Estrutura de Diretórios\")\n",
    "    \n",
    "    directories = {\n",
    "        'yolo_dataset': Path(OUTPUT_BASE) / \"yolo_dataset\",\n",
    "        'patches_dataset': Path(OUTPUT_BASE) / \"patches_dataset\"\n",
    "    }\n",
    "    \n",
    "    # Estrutura YOLO\n",
    "    yolo_base = directories['yolo_dataset']\n",
    "    for split in ['train', 'valid', 'test']:\n",
    "        (yolo_base / \"images\" / split).mkdir(parents=True, exist_ok=True)\n",
    "        (yolo_base / \"labels\" / split).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Estrutura Patches\n",
    "    patches_base = directories['patches_dataset']\n",
    "    for split in ['train', 'valid', 'test']:\n",
    "        for class_name in CLASS_NAMES:\n",
    "            (patches_base / split / class_name).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    for name, path in directories.items():\n",
    "        print(f\"    {name}: {path}\")\n",
    "    \n",
    "    return directories\n",
    "\n",
    "def create_yolo_dataset_yaml(output_dir, class_names):\n",
    "    \n",
    "    yaml_content = f\"\"\"# Dataset YOLO - TCC Células Microscópicas\n",
    "# Gerado automaticamente - Bloco 2\n",
    "\n",
    "path: {output_dir}\n",
    "train: images/train\n",
    "val: images/valid  \n",
    "test: images/test\n",
    "\n",
    "# Classes\n",
    "nc: {len(class_names)}\n",
    "names: {class_names}\n",
    "\n",
    "# Informações adicionais\n",
    "description: \"Classificação de células microscópicas com/sem corante azul de metileno\"\n",
    "version: \"1.0\"\n",
    "date: \"2025\"\n",
    "\"\"\"\n",
    "    \n",
    "    yaml_path = Path(output_dir) / \"dataset.yaml\"\n",
    "    with open(yaml_path, 'w') as f:\n",
    "        f.write(yaml_content)\n",
    "    \n",
    "    return yaml_path\n",
    "\n",
    "# 3. Visualização e Análise\n",
    "\n",
    "def visualize_annotations_sample(split_name, images_dict, annotations_list, images_path, n_samples=6):\n",
    "    \n",
    "    print(f\"\\n Visualizando Amostras - {split_name.upper()}\")    \n",
    "    \n",
    "    # Selecionar imagens aleatórias\n",
    "    image_ids = list(images_dict.keys())\n",
    "    if len(image_ids) < n_samples:\n",
    "        n_samples = len(image_ids)\n",
    "    \n",
    "    random.seed(42)  # Reprodutibilidade\n",
    "    sample_ids = random.sample(image_ids, n_samples)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    colors = {'COM_corante': 'blue', 'SEM_corante': 'red'}\n",
    "    \n",
    "    for idx, image_id in enumerate(sample_ids):\n",
    "        if idx >= len(axes):\n",
    "            break\n",
    "            \n",
    "        # Carregar imagem\n",
    "        image_info = images_dict[image_id]\n",
    "        image_path = os.path.join(images_path, image_info['file_name'])\n",
    "        image = load_image_safely(image_path)     \n",
    "        \n",
    "        # Encontrar anotações desta imagem\n",
    "        image_annotations = [ann for ann in annotations_list if ann['image_id'] == image_id]\n",
    "        \n",
    "        # Plotar imagem\n",
    "        axes[idx].imshow(image)\n",
    "        \n",
    "        # Plotar bounding boxes\n",
    "        class_counts = defaultdict(int)\n",
    "        for ann in image_annotations:\n",
    "            bbox = ann['bbox']  # [x, y, width, height]\n",
    "            binary_class = ann['binary_class']\n",
    "            class_counts[binary_class] += 1\n",
    "            \n",
    "            # Criar retângulo\n",
    "            rect = patches.Rectangle(\n",
    "                (bbox[0], bbox[1]), bbox[2], bbox[3],\n",
    "                linewidth=2, edgecolor=colors[binary_class], \n",
    "                facecolor='none', alpha=0.8\n",
    "            )\n",
    "            axes[idx].add_patch(rect)\n",
    "            \n",
    "            # Adicionar label\n",
    "            axes[idx].text(bbox[0], bbox[1]-5, binary_class, \n",
    "                          color=colors[binary_class], fontsize=8, \n",
    "                          fontweight='bold', alpha=0.9)\n",
    "        \n",
    "        # Título com estatísticas\n",
    "        title = f'{image_info[\"file_name\"]}\\n'\n",
    "        title += f'COM: {class_counts[\"COM_corante\"]}, SEM: {class_counts[\"SEM_corante\"]}'\n",
    "        axes[idx].set_title(title, fontsize=10)\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    # Ocultar axes vazios\n",
    "    for idx in range(len(sample_ids), len(axes)):\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.suptitle(f'Amostras do Split {split_name.upper()} - Bounding Boxes Anotadas', \n",
    "                 fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return sample_ids\n",
    "\n",
    "def analyze_bbox_detailed(all_annotations):\n",
    "    \n",
    "    print(f\"\\n Análise das Bounding Boxes\")    \n",
    "    \n",
    "    # Compilar todas as bounding boxes\n",
    "    all_bboxes = []\n",
    "    for split_name, annotations in all_annotations.items():\n",
    "        for ann in annotations:\n",
    "            bbox_info = {\n",
    "                'split': split_name,\n",
    "                'width': ann['bbox'][2],\n",
    "                'height': ann['bbox'][3],\n",
    "                'area': ann['area'],\n",
    "                'aspect_ratio': ann['bbox'][2] / ann['bbox'][3],\n",
    "                'binary_class': ann['binary_class']\n",
    "            }\n",
    "            all_bboxes.append(bbox_info)\n",
    "    \n",
    "    df_bbox = pd.DataFrame(all_bboxes)\n",
    "    \n",
    "    # Estatísticas gerais\n",
    "    print(f\" Estatísticas Gerais:\")\n",
    "    print(f\"   • Total de bounding boxes: {len(df_bbox)}\")\n",
    "    print(f\"   • Width  - Min: {df_bbox['width'].min():.1f}, Max: {df_bbox['width'].max():.1f}, Média: {df_bbox['width'].mean():.1f}\")\n",
    "    print(f\"   • Height - Min: {df_bbox['height'].min():.1f}, Max: {df_bbox['height'].max():.1f}, Média: {df_bbox['height'].mean():.1f}\")\n",
    "    print(f\"   • Area   - Min: {df_bbox['area'].min():.0f}, Max: {df_bbox['area'].max():.0f}, Média: {df_bbox['area'].mean():.0f}\")\n",
    "    print(f\"   • Aspect Ratio - Min: {df_bbox['aspect_ratio'].min():.2f}, Max: {df_bbox['aspect_ratio'].max():.2f}, Média: {df_bbox['aspect_ratio'].mean():.2f}\")\n",
    "    \n",
    "    # Por classe\n",
    "    print(f\"\\n POR CLASSE:\")\n",
    "    for cls in df_bbox['binary_class'].unique():\n",
    "        subset = df_bbox[df_bbox['binary_class'] == cls]\n",
    "        print(f\"   {cls} ({len(subset)} boxes):\")\n",
    "        print(f\"     • Width: {subset['width'].mean():.1f} ± {subset['width'].std():.1f}\")\n",
    "        print(f\"     • Height: {subset['height'].mean():.1f} ± {subset['height'].std():.1f}\")\n",
    "        print(f\"     • Area: {subset['area'].mean():.0f} ± {subset['area'].std():.0f}\")\n",
    "    \n",
    "    # Detecção de outliers e filtros automáticos\n",
    "    q1_area = df_bbox['area'].quantile(0.25)\n",
    "    q3_area = df_bbox['area'].quantile(0.75)\n",
    "    iqr = q3_area - q1_area\n",
    "    lower_bound = q1_area - 1.5 * iqr\n",
    "    upper_bound = q3_area + 1.5 * iqr\n",
    "    \n",
    "    outliers = df_bbox[(df_bbox['area'] < lower_bound) | (df_bbox['area'] > upper_bound)]\n",
    "    print(f\"\\n Detecção de Outliers:\")\n",
    "    print(f\"   • Outliers por área: {len(outliers)} ({len(outliers)/len(df_bbox)*100:.1f}%)\")\n",
    "    \n",
    "    # Filtros automáticos baseados em percentis\n",
    "    min_area_rec = df_bbox['area'].quantile(0.05)  # 5% menores\n",
    "    max_area_rec = df_bbox['area'].quantile(0.95)  # 5% maiores\n",
    "    min_aspect_rec = df_bbox['aspect_ratio'].quantile(0.05)\n",
    "    max_aspect_rec = df_bbox['aspect_ratio'].quantile(0.95)\n",
    "    \n",
    "    quality_filters = {\n",
    "        'min_area': min_area_rec,\n",
    "        'max_area': max_area_rec,\n",
    "        'min_aspect': max(0.3, min_aspect_rec),  # Não muito estreito\n",
    "        'max_aspect': min(3.0, max_aspect_rec)   # Não muito alongado\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n Filtros de Qualidade:\")\n",
    "    for key, value in quality_filters.items():\n",
    "        print(f\"   • {key}: {value:.1f}\")\n",
    "    \n",
    "    # Visualizações\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    \n",
    "    colors = {'COM_corante': 'blue', 'SEM_corante': 'red'}\n",
    "    \n",
    "    # 1. Distribuição de áreas\n",
    "    for cls in df_bbox['binary_class'].unique():\n",
    "        subset = df_bbox[df_bbox['binary_class'] == cls]\n",
    "        axes[0,0].hist(subset['area'], alpha=0.6, label=cls, \n",
    "                       bins=30, color=colors[cls])\n",
    "    axes[0,0].axvline(min_area_rec, color='green', linestyle='--', alpha=0.7, label='Min recomendado')\n",
    "    axes[0,0].axvline(max_area_rec, color='green', linestyle='--', alpha=0.7, label='Max recomendado')\n",
    "    axes[0,0].set_title('Distribuição de Áreas')\n",
    "    axes[0,0].set_xlabel('Área (pixels²)')\n",
    "    axes[0,0].legend()\n",
    "    \n",
    "    # 2. Width vs Height scatter\n",
    "    for cls in df_bbox['binary_class'].unique():\n",
    "        subset = df_bbox[df_bbox['binary_class'] == cls]\n",
    "        axes[0,1].scatter(subset['width'], subset['height'], \n",
    "                         alpha=0.6, label=cls, color=colors[cls])\n",
    "    axes[0,1].plot([0, 200], [0, 200], 'k--', alpha=0.5, label='Quadrado perfeito')\n",
    "    axes[0,1].set_title('Width vs Height')\n",
    "    axes[0,1].set_xlabel('Width (pixels)')\n",
    "    axes[0,1].set_ylabel('Height (pixels)')\n",
    "    axes[0,1].legend()\n",
    "    \n",
    "    # 3. Aspect ratio\n",
    "    for cls in df_bbox['binary_class'].unique():\n",
    "        subset = df_bbox[df_bbox['binary_class'] == cls]\n",
    "        axes[0,2].hist(subset['aspect_ratio'], alpha=0.6, label=cls, \n",
    "                       bins=20, color=colors[cls])\n",
    "    axes[0,2].axvline(quality_filters['min_aspect'], color='green', linestyle='--', alpha=0.7)\n",
    "    axes[0,2].axvline(quality_filters['max_aspect'], color='green', linestyle='--', alpha=0.7)\n",
    "    axes[0,2].set_title('Distribuição de Aspect Ratio')\n",
    "    axes[0,2].set_xlabel('Aspect Ratio (W/H)')\n",
    "    axes[0,2].legend()\n",
    "    \n",
    "    # 4. Boxplot de áreas por classe\n",
    "    data_for_box = [df_bbox[df_bbox['binary_class'] == cls]['area'] for cls in df_bbox['binary_class'].unique()]\n",
    "    axes[1,0].boxplot(data_for_box, labels=df_bbox['binary_class'].unique())\n",
    "    axes[1,0].set_title('Boxplot - Áreas por Classe')\n",
    "    axes[1,0].set_ylabel('Área (pixels²)')\n",
    "    \n",
    "    # 5. Distribuição por split\n",
    "    split_counts = df_bbox['split'].value_counts()\n",
    "    axes[1,1].bar(split_counts.index, split_counts.values, alpha=0.7)\n",
    "    axes[1,1].set_title('Distribuição por Split')\n",
    "    axes[1,1].set_ylabel('Número de Bounding Boxes')\n",
    "    \n",
    "    # 6. Área vs Aspect Ratio\n",
    "    scatter = axes[1,2].scatter(df_bbox['area'], df_bbox['aspect_ratio'], \n",
    "                               c=[colors[cls] for cls in df_bbox['binary_class']], \n",
    "                               alpha=0.6)\n",
    "    axes[1,2].set_title('Área vs Aspect Ratio')\n",
    "    axes[1,2].set_xlabel('Área (pixels²)')\n",
    "    axes[1,2].set_ylabel('Aspect Ratio')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return df_bbox, quality_filters\n",
    "\n",
    "\n",
    "# 4. Conversão e Extração\n",
    "\n",
    "\n",
    "def copy_images_for_yolo(source_images_path, target_images_path, images_dict):\n",
    "    \n",
    "    copied_count = 0\n",
    "    failed_count = 0\n",
    "    \n",
    "    for image_info in images_dict.values():\n",
    "        source_path = Path(source_images_path) / image_info['file_name']\n",
    "        target_path = Path(target_images_path) / image_info['file_name']\n",
    "        \n",
    "        try:\n",
    "            if source_path.exists():\n",
    "                shutil.copy2(source_path, target_path)\n",
    "                copied_count += 1\n",
    "            else:\n",
    "                failed_count += 1\n",
    "        except Exception as e:\n",
    "            failed_count += 1\n",
    "    \n",
    "    return copied_count, failed_count\n",
    "\n",
    "def convert_and_extract_unified(annotations_list, images_dict, images_path, \n",
    "                               yolo_labels_path, patches_base_path, split_name, \n",
    "                               patch_size, quality_filters):\n",
    "    \n",
    "    print(f\"    Processando {split_name}...\")\n",
    "    \n",
    "    # Contadores\n",
    "    yolo_annotations = 0\n",
    "    patches_extracted = 0\n",
    "    filtered_count = 0\n",
    "    class_counts = defaultdict(int)\n",
    "    \n",
    "    # Agrupar anotações por imagem para processar uma vez\n",
    "    annotations_by_image = defaultdict(list)\n",
    "    for ann in annotations_list:\n",
    "        annotations_by_image[ann['image_id']].append(ann)\n",
    "    \n",
    "    for image_id, image_annotations in annotations_by_image.items():\n",
    "        if image_id not in images_dict:\n",
    "            continue\n",
    "            \n",
    "        image_info = images_dict[image_id]\n",
    "        image_width = image_info['width']\n",
    "        image_height = image_info['height']\n",
    "        \n",
    "        # Carregar imagem uma única vez\n",
    "        image_path = Path(images_path) / image_info['file_name']\n",
    "        if not image_path.exists():\n",
    "            continue\n",
    "            \n",
    "        image = cv2.imread(str(image_path))\n",
    "        if image is None:\n",
    "            continue\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Filtrar anotações válidas\n",
    "        valid_annotations = []\n",
    "        yolo_lines = []\n",
    "        \n",
    "        for idx, ann in enumerate(image_annotations):\n",
    "            bbox = ann['bbox']\n",
    "            area = ann['area']\n",
    "            aspect_ratio = bbox[2] / bbox[3]\n",
    "            binary_class = ann['binary_class']\n",
    "            \n",
    "            # Aplicar filtros de qualidade\n",
    "            if not (area >= quality_filters['min_area'] and \n",
    "                   area <= quality_filters['max_area'] and\n",
    "                   aspect_ratio >= quality_filters['min_aspect'] and \n",
    "                   aspect_ratio <= quality_filters['max_aspect']):\n",
    "                filtered_count += 1\n",
    "                continue\n",
    "            \n",
    "            valid_annotations.append((ann, idx))\n",
    "            \n",
    "            # Preparar linha YOLO\n",
    "            x_center = (bbox[0] + bbox[2] / 2) / image_width\n",
    "            y_center = (bbox[1] + bbox[3] / 2) / image_height\n",
    "            width_norm = bbox[2] / image_width\n",
    "            height_norm = bbox[3] / image_height\n",
    "            class_id = CLASS_MAPPING_REVERSE[binary_class]\n",
    "            \n",
    "            yolo_lines.append(f\"{class_id} {x_center:.6f} {y_center:.6f} {width_norm:.6f} {height_norm:.6f}\")\n",
    "        \n",
    "        # Se não há anotações válidas, pular esta imagem\n",
    "        if not valid_annotations:\n",
    "            continue\n",
    "        \n",
    "        # Salvar arquivo YOLO\n",
    "        yolo_filename = Path(image_info['file_name']).stem + '.txt'\n",
    "        yolo_path = yolo_labels_path / yolo_filename\n",
    "        \n",
    "        with open(yolo_path, 'w') as f:\n",
    "            for line in yolo_lines:\n",
    "                f.write(line + '\\n')\n",
    "                yolo_annotations += 1\n",
    "        \n",
    "        # Extrair patches\n",
    "        for ann, idx in valid_annotations:\n",
    "            bbox = ann['bbox']\n",
    "            binary_class = ann['binary_class']\n",
    "            \n",
    "            # Extrair patch\n",
    "            x, y, w, h = map(int, bbox)\n",
    "            \n",
    "            # Garantir bounds\n",
    "            x1 = max(0, x)\n",
    "            y1 = max(0, y)\n",
    "            x2 = min(image_rgb.shape[1], x + w)\n",
    "            y2 = min(image_rgb.shape[0], y + h)\n",
    "            \n",
    "            if x2 <= x1 or y2 <= y1:\n",
    "                continue\n",
    "            \n",
    "            # Extrair e redimensionar patch\n",
    "            patch = image_rgb[y1:y2, x1:x2]\n",
    "            patch_resized = cv2.resize(patch, (patch_size, patch_size))\n",
    "            \n",
    "            # Salvar patch\n",
    "            image_basename = Path(image_info['file_name']).stem\n",
    "            patch_filename = f\"{image_basename}_{idx:03d}_{binary_class}.jpg\"\n",
    "            patch_output_dir = patches_base_path / split_name / binary_class\n",
    "            patch_path = patch_output_dir / patch_filename\n",
    "            \n",
    "            # Converter RGB para BGR para cv2.imwrite\n",
    "            patch_bgr = cv2.cvtColor(patch_resized, cv2.COLOR_RGB2BGR)\n",
    "            cv2.imwrite(str(patch_path), patch_bgr)\n",
    "            \n",
    "            patches_extracted += 1\n",
    "            class_counts[binary_class] += 1\n",
    "    \n",
    "    return yolo_annotations, patches_extracted, filtered_count, dict(class_counts)\n",
    "\n",
    "\n",
    "# 5. Função Principal\n",
    "\n",
    "\n",
    "def main_data_preparation():\n",
    "    \n",
    "    print(f\"\\n Iniciando Preparação Completa dos Dados\")    \n",
    "        \n",
    "    # Etapa 1: Visualização e Análise\n",
    "    print(f\"\\n Etapa 1: Visualização e Análise\")    \n",
    "    \n",
    "    # Visualizar amostras de cada split\n",
    "    sample_results = {}\n",
    "    for split_name in ['train', 'valid', 'test']:\n",
    "        if split_name in all_annotations and len(all_annotations[split_name]) > 0:\n",
    "            json_path = PATHS[split_name]['json']\n",
    "            images_path = PATHS[split_name]['images']\n",
    "            \n",
    "            with open(json_path, 'r') as f:\n",
    "                coco_data = json.load(f)\n",
    "            images_dict = {img['id']: img for img in coco_data['images']}\n",
    "            \n",
    "            sample_ids = visualize_annotations_sample(\n",
    "                split_name, images_dict, all_annotations[split_name], \n",
    "                images_path, n_samples=6\n",
    "            )\n",
    "            sample_results[split_name] = sample_ids\n",
    "    \n",
    "    # Análise detalhada das bounding boxes\n",
    "    df_bbox, quality_filters = analyze_bbox_detailed(all_annotations)\n",
    "    \n",
    "    print(f\"\\n Filtros Definidos:\")\n",
    "    for key, value in quality_filters.items():\n",
    "        print(f\"   • {key}: {value:.1f}\")\n",
    "    \n",
    "    # Etapa 2: Conversão e Extração\n",
    "    print(f\"\\n Etapa 2: Conversão e Extração\")    \n",
    "    \n",
    "    # Criar diretórios\n",
    "    directories = create_directories()\n",
    "    \n",
    "    # Processar cada split\n",
    "    total_stats = {\n",
    "        'yolo_annotations': 0,\n",
    "        'patches_extracted': 0,\n",
    "        'filtered_total': 0,\n",
    "        'class_counts': defaultdict(int)\n",
    "    }\n",
    "    \n",
    "    for split_name in ['train', 'valid', 'test']:\n",
    "        if split_name not in all_annotations:\n",
    "            print(f\" Split {split_name} não encontrado, pulando...\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\n Processando Split: {split_name.upper()}\")\n",
    "        \n",
    "        # Carregar dados COCO do split\n",
    "        json_path = PATHS[split_name]['json']\n",
    "        images_path = PATHS[split_name]['images']\n",
    "        \n",
    "        with open(json_path, 'r') as f:\n",
    "            coco_data = json.load(f)\n",
    "        images_dict = {img['id']: img for img in coco_data['images']}\n",
    "        annotations_list = all_annotations[split_name]\n",
    "        \n",
    "        print(f\"    Dados originais: {len(images_dict)} imagens, {len(annotations_list)} anotações\")\n",
    "        \n",
    "        # Copiar imagens para YOLO\n",
    "        yolo_images_path = directories['yolo_dataset'] / \"images\" / split_name\n",
    "        copied, failed = copy_images_for_yolo(images_path, yolo_images_path, images_dict)\n",
    "        print(f\"    Imagens copiadas: {copied}, Falhas: {failed}\")\n",
    "        \n",
    "        # Conversão e extração unificada\n",
    "        yolo_labels_path = directories['yolo_dataset'] / \"labels\" / split_name\n",
    "        \n",
    "        yolo_ann, patches_ext, filtered, class_counts = convert_and_extract_unified(\n",
    "            annotations_list, images_dict, images_path,\n",
    "            yolo_labels_path, directories['patches_dataset'], split_name,\n",
    "            PATCH_SIZE, quality_filters\n",
    "        )\n",
    "        \n",
    "        print(f\"    YOLO - Anotações: {yolo_ann}\")\n",
    "        print(f\"    PATCHES - Extraídos: {patches_ext}, Filtrados: {filtered}\")\n",
    "        for class_name, count in class_counts.items():\n",
    "            print(f\"      • {class_name}: {count} patches\")\n",
    "        \n",
    "        # Atualizar estatísticas totais\n",
    "        total_stats['yolo_annotations'] += yolo_ann\n",
    "        total_stats['patches_extracted'] += patches_ext\n",
    "        total_stats['filtered_total'] += filtered\n",
    "        for class_name, count in class_counts.items():\n",
    "            total_stats['class_counts'][class_name] += count\n",
    "    \n",
    "    # Etapa 3: Finalização\n",
    "    print(f\"\\n Etapa 3: Finalização\")    \n",
    "    \n",
    "    # Criar arquivo YAML para YOLO\n",
    "    yaml_path = create_yolo_dataset_yaml(directories['yolo_dataset'], CLASS_NAMES)\n",
    "    print(f\" Dataset YAML criado: {yaml_path}\")\n",
    "    \n",
    "    # Relatório Final\n",
    "    print(f\"\\n\")\n",
    "    print(\" Relatório Final de Preparação de Dados\")    \n",
    "    \n",
    "    print(f\"\\n Dataset YOLO:\")\n",
    "    print(f\"   • Anotações processadas: {total_stats['yolo_annotations']}\")\n",
    "    print(f\"   • Localização: {directories['yolo_dataset']}\")\n",
    "    \n",
    "    print(f\"\\n Dataset Patches:\")\n",
    "    print(f\"   • Patches extraídos: {total_stats['patches_extracted']}\")\n",
    "    print(f\"   • Patches filtrados: {total_stats['filtered_total']}\")\n",
    "    \n",
    "    if total_stats['patches_extracted'] + total_stats['filtered_total'] > 0:\n",
    "        aproveitamento = total_stats['patches_extracted'] / (total_stats['patches_extracted'] + total_stats['filtered_total']) * 100\n",
    "        print(f\"   • Taxa de aproveitamento: {aproveitamento:.1f}%\")\n",
    "    \n",
    "    total_patches = sum(total_stats['class_counts'].values())\n",
    "    for class_name, count in total_stats['class_counts'].items():\n",
    "        if total_patches > 0:\n",
    "            pct = (count / total_patches) * 100\n",
    "            print(f\"   • {class_name}: {count} patches ({pct:.1f}%)\")\n",
    "    \n",
    "    print(f\"   • Localização: {directories['patches_dataset']}\")\n",
    "    \n",
    "    # Verificação de balanceamento\n",
    "    if total_stats['class_counts']:\n",
    "        com_patches = total_stats['class_counts']['COM_corante']\n",
    "        sem_patches = total_stats['class_counts']['SEM_corante']\n",
    "        if com_patches > 0 and sem_patches > 0:\n",
    "            balance_ratio = min(com_patches, sem_patches) / max(com_patches, sem_patches)\n",
    "            \n",
    "            print(f\"\\n Balanceamento:\")\n",
    "            print(f\"   • Ratio de balanceamento: {balance_ratio:.3f}\")\n",
    "            if balance_ratio > 0.8:\n",
    "                print(\"   • Status: Excelente balanceamento\")\n",
    "            elif balance_ratio > 0.6:\n",
    "                print(\"   • Status: Balanceamento aceitável\")\n",
    "            else:\n",
    "                print(\"   • Status: Desbalanceamento detectado\")\n",
    "    \n",
    "    print(f\"\\n\")\n",
    "    print(\" Bloco 2 Concluído\")\n",
    "    print(\" Datasets YOLO e Patches prontos para treinamento\")    \n",
    "    \n",
    "    return True, directories, quality_filters, total_stats\n",
    "\n",
    "# 6. Execução\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Executar preparação completa dos dados\n",
    "    success, directories, filters, stats = main_data_preparation()\n",
    "    \n",
    "    if success:        \n",
    "        print(\"   Dados organizados e filtrados\")        \n",
    "        \n",
    "        # Salvar informações importantes para os próximos blocos\n",
    "        preparation_info = {\n",
    "            'directories': {str(k): str(v) for k, v in directories.items()},\n",
    "            'quality_filters': filters,\n",
    "            'statistics': dict(stats),\n",
    "            'patch_size': PATCH_SIZE,\n",
    "            'class_names': CLASS_NAMES\n",
    "        }\n",
    "        \n",
    "        # Salvar em arquivo JSON para uso posterior\n",
    "        info_path = Path(OUTPUT_BASE) / \"preparation_info.json\"\n",
    "        with open(info_path, 'w') as f:\n",
    "            json.dump(preparation_info, f, indent=2, default=str)\n",
    "        \n",
    "        print(f\"   Informações salvas em: {info_path}\")\n",
    "    else:\n",
    "        print(f\"\\n  Execute os blocos anteriores primeiro!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-25T00:47:43.133470Z",
     "iopub.status.busy": "2025-06-25T00:47:43.132989Z",
     "iopub.status.idle": "2025-06-25T00:47:43.163453Z",
     "shell.execute_reply": "2025-06-25T00:47:43.162904Z",
     "shell.execute_reply.started": "2025-06-25T00:47:43.133446Z"
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Bloco 3: Treinamento do Detector YOLO\n",
    "# Pipeline: YOLO (Detecção e Classificação)\n",
    "\n",
    "print(\" BLOCO 3: Treinamento do Detector YOLO\")\n",
    "print(\" Objetivo: Fine-tuning YOLOv8 para detecção de células\")\n",
    "\n",
    "# 1. Instalação e Setup do Ultralytics YOLO\n",
    "\n",
    "def install_and_setup_yolo():\n",
    "    \n",
    "    print(f\"\\n Setup do Ambiente YOLO\")        \n",
    "    \n",
    "    # Verificar GPU\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    print(f\"    Dispositivo: {device}\")\n",
    "    \n",
    "    if device == 'cuda':\n",
    "        print(f\"    GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"    VRAM disponível: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "    \n",
    "    return YOLO, device\n",
    "\n",
    "# 2. Configuração de Treinamento\n",
    "\n",
    "# Configurações otimizadas para GPU P100 do Kaggle\n",
    "TRAINING_CONFIG = {\n",
    "    'model_size': 'yolov8s.pt',  # Small - balanceado para P100\n",
    "    'epochs': 100,               # Máximo, com early stopping\n",
    "    'batch_size': 16,            # Otimizado para P100\n",
    "    'imgsz': 640,                # Tamanho padrão das imagens\n",
    "    'patience': 15,              # Early stopping\n",
    "    'save_period': 10,           # Salvar checkpoint a cada 10 epochs\n",
    "    'optimizer': 'AdamW',        # Otimizador moderno\n",
    "    'lr0': 0.01,                 # Learning rate inicial\n",
    "    'lrf': 0.1,                  # Learning rate final (decay)\n",
    "    'momentum': 0.937,           # Momentum para SGD\n",
    "    'weight_decay': 0.0005,      # Regularização\n",
    "    'warmup_epochs': 3,          # Epochs de warmup\n",
    "    'warmup_momentum': 0.8,      # Momentum durante warmup\n",
    "    'box': 7.5,                  # Box loss gain\n",
    "    'cls': 0.5,                  # Class loss gain\n",
    "    'dfl': 1.5,                  # DFL loss gain\n",
    "    'mixup': 0.0,                # Mixup augmentation (off para microscopia)\n",
    "    'copy_paste': 0.0,           # Copy paste augmentation (off)\n",
    "    'degrees': 10.0,             # Rotação máxima (graus)\n",
    "    'translate': 0.1,            # Translação máxima (fração)\n",
    "    'scale': 0.5,                # Scale variation (+/- gain)\n",
    "    'shear': 2.0,                # Shear máximo (graus)\n",
    "    'perspective': 0.0,          # Perspective transform (off para microscopia)\n",
    "    'flipud': 0.0,               # Flip vertical probability (off)\n",
    "    'fliplr': 0.5,               # Flip horizontal probability\n",
    "    'mosaic': 0.0,               # Mosaic augmentation (off para microscopia)\n",
    "    'hsv_h': 0.015,              # Hue augmentation (small para microscopia)\n",
    "    'hsv_s': 0.7,                # Saturation augmentation\n",
    "    'hsv_v': 0.4                 # Value augmentation\n",
    "}\n",
    "\n",
    "DATASET_PATH = \"/kaggle/working/yolo_dataset\"\n",
    "OUTPUT_PATH = \"/kaggle/working/yolo_training\"\n",
    "\n",
    "print(f\" Configuração de Treinamento:\")\n",
    "print(f\"   • Modelo: {TRAINING_CONFIG['model_size']}\")\n",
    "print(f\"   • Epochs máximos: {TRAINING_CONFIG['epochs']}\")\n",
    "print(f\"   • Batch size: {TRAINING_CONFIG['batch_size']}\")\n",
    "print(f\"   • Early stopping: {TRAINING_CONFIG['patience']} epochs\")\n",
    "print(f\"   • Dataset: {DATASET_PATH}\")\n",
    "print(f\"   • Saída: {OUTPUT_PATH}\")\n",
    "\n",
    "# 3. Funções de Monitoramento e Análise\n",
    "\n",
    "def setup_training_monitoring():\n",
    "    \n",
    "    # Criar diretório de saída\n",
    "    Path(OUTPUT_PATH).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Configurar logging\n",
    "    training_log = {\n",
    "        'start_time': time.time(),\n",
    "        'epochs_completed': 0,\n",
    "        'best_map50': 0.0,\n",
    "        'best_map50_95': 0.0,\n",
    "        'training_metrics': [],\n",
    "        'validation_metrics': [],\n",
    "        'overfitting_alerts': []\n",
    "    }\n",
    "    \n",
    "    return training_log\n",
    "\n",
    "def analyze_training_progress(results_path):\n",
    "    \n",
    "    print(f\"\\n Analisando Progresso do Treinamento\")    \n",
    "    \n",
    "    # Carregar resultados\n",
    "    results_file = Path(results_path) / \"results.csv\" \n",
    "    \n",
    "    \n",
    "    df = pd.read_csv(results_file)\n",
    "    \n",
    "    # Renomear colunas com espaços em branco\n",
    "    df.columns = df.columns.str.strip()\n",
    "    \n",
    "    print(f\"    Epochs processados: {len(df)}\")\n",
    "    \n",
    "    # Métricas principais\n",
    "    if len(df) > 0:\n",
    "        latest = df.iloc[-1]\n",
    "        print(f\"    Último epoch:\")\n",
    "        print(f\"      • Train Loss: {latest.get('train/box_loss', 0):.4f}\")\n",
    "        print(f\"      • Val Loss: {latest.get('val/box_loss', 0):.4f}\")\n",
    "        print(f\"      • mAP@0.5: {latest.get('metrics/mAP50(B)', 0):.4f}\")\n",
    "        print(f\"      • mAP@0.5:0.95: {latest.get('metrics/mAP50-95(B)', 0):.4f}\")\n",
    "        \n",
    "        # Detectar overfitting (últimos 5 epochs)\n",
    "        if len(df) >= 10:\n",
    "            recent_train = df['train/box_loss'].tail(5).mean()\n",
    "            recent_val = df['val/box_loss'].tail(5).mean()\n",
    "            overfitting_ratio = recent_val / recent_train\n",
    "            \n",
    "            print(f\"    Análise de Overfitting:\")\n",
    "            print(f\"      • Ratio Val/Train Loss: {overfitting_ratio:.3f}\")\n",
    "            \n",
    "            if overfitting_ratio > 1.5:\n",
    "                print(\"       ALERTA: Possível overfitting detectado!\")\n",
    "            elif overfitting_ratio > 1.2:\n",
    "                print(\"       Monitore: Val loss começando a divergir\")\n",
    "            else:\n",
    "                print(\"       Sem sinais de overfitting\")\n",
    "    \n",
    "    return df\n",
    "        \n",
    "    \n",
    "\n",
    "def plot_training_curves(results_df, output_path):\n",
    "    \n",
    "    print(f\"    Gerando gráficos de treinamento...\")\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    epochs = range(len(results_df))\n",
    "    \n",
    "    # 1. Box Loss\n",
    "    if 'train/box_loss' in results_df.columns and 'val/box_loss' in results_df.columns:\n",
    "        axes[0,0].plot(epochs, results_df['train/box_loss'], label='Train', color='blue')\n",
    "        axes[0,0].plot(epochs, results_df['val/box_loss'], label='Validation', color='red')\n",
    "        axes[0,0].set_title('Box Loss')\n",
    "        axes[0,0].set_xlabel('Epoch')\n",
    "        axes[0,0].set_ylabel('Loss')\n",
    "        axes[0,0].legend()\n",
    "        axes[0,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Class Loss\n",
    "    if 'train/cls_loss' in results_df.columns and 'val/cls_loss' in results_df.columns:\n",
    "        axes[0,1].plot(epochs, results_df['train/cls_loss'], label='Train', color='blue')\n",
    "        axes[0,1].plot(epochs, results_df['val/cls_loss'], label='Validation', color='red')\n",
    "        axes[0,1].set_title('Classification Loss')\n",
    "        axes[0,1].set_xlabel('Epoch')\n",
    "        axes[0,1].set_ylabel('Loss')\n",
    "        axes[0,1].legend()\n",
    "        axes[0,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. mAP Metrics\n",
    "    if 'metrics/mAP50(B)' in results_df.columns:\n",
    "        axes[1,0].plot(epochs, results_df['metrics/mAP50(B)'], label='mAP@0.5', color='green')\n",
    "        if 'metrics/mAP50-95(B)' in results_df.columns:\n",
    "            axes[1,0].plot(epochs, results_df['metrics/mAP50-95(B)'], label='mAP@0.5:0.95', color='orange')\n",
    "        axes[1,0].set_title('mAP Metrics')\n",
    "        axes[1,0].set_xlabel('Epoch')\n",
    "        axes[1,0].set_ylabel('mAP')\n",
    "        axes[1,0].legend()\n",
    "        axes[1,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Precision/Recall\n",
    "    if 'metrics/precision(B)' in results_df.columns and 'metrics/recall(B)' in results_df.columns:\n",
    "        axes[1,1].plot(epochs, results_df['metrics/precision(B)'], label='Precision', color='purple')\n",
    "        axes[1,1].plot(epochs, results_df['metrics/recall(B)'], label='Recall', color='brown')\n",
    "        axes[1,1].set_title('Precision & Recall')\n",
    "        axes[1,1].set_xlabel('Epoch')\n",
    "        axes[1,1].set_ylabel('Score')\n",
    "        axes[1,1].legend()\n",
    "        axes[1,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Salvar gráfico\n",
    "    plot_path = Path(output_path) / \"training_curves.png\"\n",
    "    plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"    Gráficos salvos em: {plot_path}\")\n",
    "\n",
    "def validate_dataset_yaml():\n",
    "   \n",
    "    yaml_path = Path(DATASET_PATH) / \"dataset.yaml\"    \n",
    "       \n",
    "    with open(yaml_path, 'r') as f:\n",
    "        data = yaml.safe_load(f)\n",
    "    \n",
    "    print(f\" Dataset YAML validado:\")\n",
    "    print(f\"   • Path: {data.get('path')}\")\n",
    "    print(f\"   • Classes: {data.get('nc')} - {data.get('names')}\")\n",
    "    print(f\"   • Splits: train, val, test\")    \n",
    "\n",
    "# 4. Função Principal de Treinamento\n",
    "\n",
    "def train_yolo_detector():\n",
    "   \n",
    "    print(f\"\\n Iniciando Treinamento do Detector YOLO\")    \n",
    "    \n",
    "    # 1. Setup inicial\n",
    "    YOLO, device = install_and_setup_yolo()\n",
    "            \n",
    "    # 2. Setup de monitoramento\n",
    "    training_log = setup_training_monitoring()\n",
    "    \n",
    "    # 3. Carregar modelo pré-treinado\n",
    "    print(f\"\\n Carregamento Modelo Pré-Treinado\")        \n",
    "    \n",
    "    model = YOLO(TRAINING_CONFIG['model_size'])\n",
    "    print(f\"    Modelo {TRAINING_CONFIG['model_size']} carregado\")\n",
    "    print(f\"    Parâmetros: {sum(p.numel() for p in model.model.parameters()):,}\")   \n",
    "    \n",
    "    # 4. Configurar argumentos de treinamento\n",
    "    train_args = {\n",
    "        'data': str(Path(DATASET_PATH) / \"dataset.yaml\"),\n",
    "        'epochs': TRAINING_CONFIG['epochs'],\n",
    "        'batch': TRAINING_CONFIG['batch_size'],\n",
    "        'imgsz': TRAINING_CONFIG['imgsz'],\n",
    "        'device': device,\n",
    "        'project': OUTPUT_PATH,\n",
    "        'name': 'cell_detector_v1',\n",
    "        'patience': TRAINING_CONFIG['patience'],\n",
    "        'save_period': TRAINING_CONFIG['save_period'],\n",
    "        'optimizer': TRAINING_CONFIG['optimizer'],\n",
    "        'lr0': TRAINING_CONFIG['lr0'],\n",
    "        'lrf': TRAINING_CONFIG['lrf'],\n",
    "        'momentum': TRAINING_CONFIG['momentum'],\n",
    "        'weight_decay': TRAINING_CONFIG['weight_decay'],\n",
    "        'warmup_epochs': TRAINING_CONFIG['warmup_epochs'],\n",
    "        'warmup_momentum': TRAINING_CONFIG['warmup_momentum'],\n",
    "        'box': TRAINING_CONFIG['box'],\n",
    "        'cls': TRAINING_CONFIG['cls'],\n",
    "        'dfl': TRAINING_CONFIG['dfl'],\n",
    "        'degrees': TRAINING_CONFIG['degrees'],\n",
    "        'translate': TRAINING_CONFIG['translate'],\n",
    "        'scale': TRAINING_CONFIG['scale'],\n",
    "        'shear': TRAINING_CONFIG['shear'],\n",
    "        'perspective': TRAINING_CONFIG['perspective'],\n",
    "        'flipud': TRAINING_CONFIG['flipud'],\n",
    "        'fliplr': TRAINING_CONFIG['fliplr'],\n",
    "        'mosaic': TRAINING_CONFIG['mosaic'],\n",
    "        'mixup': TRAINING_CONFIG['mixup'],\n",
    "        'copy_paste': TRAINING_CONFIG['copy_paste'],\n",
    "        'hsv_h': TRAINING_CONFIG['hsv_h'],\n",
    "        'hsv_s': TRAINING_CONFIG['hsv_s'],\n",
    "        'hsv_v': TRAINING_CONFIG['hsv_v'],\n",
    "        'verbose': True,\n",
    "        'seed': 42,  # Reprodutibilidade\n",
    "        'deterministic': True,\n",
    "        'single_cls': False,\n",
    "        'rect': False,\n",
    "        'cos_lr': True,  # Cosine learning rate scheduler\n",
    "        'close_mosaic': 10,  # Disable mosaic in last N epochs\n",
    "        'resume': False,\n",
    "        'amp': True,  # Automatic Mixed Precision\n",
    "        'fraction': 1.0,  # Dataset fraction to use\n",
    "        'profile': False,\n",
    "        'freeze': None,  # Freeze layers\n",
    "        'multi_scale': False,  # Multi-scale training\n",
    "        'overlap_mask': True,\n",
    "        'mask_ratio': 4,\n",
    "        'dropout': 0.0,\n",
    "        'val': True,  # Validate during training\n",
    "        'plots': True,  # Generate plots\n",
    "        'save_json': True,  # Save results in JSON format\n",
    "        'save_hybrid': False,\n",
    "        'conf': None,  # Confidence threshold for predictions\n",
    "        'iou': 0.7,  # IoU threshold for NMS\n",
    "        'max_det': 300,  # Maximum detections per image\n",
    "        'half': False,  # Use half precision\n",
    "        'dnn': False,  # Use OpenCV DNN backend\n",
    "        'cache': False,  # Use dataset caching\n",
    "        'rect': False,  # Rectangular training\n",
    "        'save_txt': False,  # Save results as txt\n",
    "        'save_conf': False,  # Save confidences in txt\n",
    "        'save_crop': False,  # Save cropped prediction boxes\n",
    "        'show_labels': True,  # Show labels in plots\n",
    "        'show_conf': True,  # Show confidences in plots\n",
    "        'visualize': False,  # Visualize model predictions\n",
    "        'augment': False,  # Apply augmentation during validation\n",
    "        'agnostic_nms': False,  # Class-agnostic NMS\n",
    "        'retina_masks': False,  # Use high resolution masks\n",
    "        'boxes': True  # Show boxes in segmentation predictions\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n Configuração de Treinamento:\")\n",
    "    print(f\"   • Dataset: {train_args['data']}\")\n",
    "    print(f\"   • Epochs: {train_args['epochs']} (early stop: {train_args['patience']})\")\n",
    "    print(f\"   • Batch size: {train_args['batch']}\")\n",
    "    print(f\"   • Image size: {train_args['imgsz']}\")\n",
    "    print(f\"   • Device: {train_args['device']}\")\n",
    "    print(f\"   • Optimizer: {train_args['optimizer']}\")\n",
    "    print(f\"   • Learning rate: {train_args['lr0']} → {train_args['lrf']}\")\n",
    "    \n",
    "    # 5. Iniciar treinamento\n",
    "    print(f\"\\n Iniciando Treinamento...\")    \n",
    "    print(f\" Monitoramento: Execute analyze_training_progress() em paralelo\")\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        # Registrar início\n",
    "        training_log['start_time'] = time.time()\n",
    "        \n",
    "        # TREINAR MODELO\n",
    "        results = model.train(**train_args)\n",
    "        \n",
    "        # Registrar fim\n",
    "        training_duration = time.time() - training_log['start_time']\n",
    "        \n",
    "        print(f\"\\n TREINAMENTO CONCLUÍDO!\")\n",
    "        \n",
    "        print(f\" Duração total: {training_duration/60:.1f} minutos\")\n",
    "        \n",
    "        # Analisar resultados finais\n",
    "        results_path = Path(OUTPUT_PATH) / \"cell_detector_v2\"\n",
    "        final_results = analyze_training_progress(results_path)\n",
    "        \n",
    "        if final_results is not None:\n",
    "            plot_training_curves(final_results, results_path)\n",
    "        \n",
    "        # Informações do modelo final - Corrigir path real\n",
    "        actual_results_path = Path(OUTPUT_PATH) / \"cell_detector_v2\"  # Path real gerado\n",
    "        best_model_path = actual_results_path / \"weights\" / \"best.pt\"\n",
    "        last_model_path = actual_results_path / \"weights\" / \"last.pt\"\n",
    "        \n",
    "        print(f\"\\n MODELOS SALVOS:\")\n",
    "        print(f\"    Melhor modelo: {best_model_path}\")\n",
    "        print(f\"    Último modelo: {last_model_path}\")\n",
    "        \n",
    "        # Métricas finais\n",
    "        if final_results is not None and len(final_results) > 0:\n",
    "            best_map50 = final_results['metrics/mAP50(B)'].max()\n",
    "            best_map50_95 = final_results['metrics/mAP50-95(B)'].max()\n",
    "            \n",
    "            print(f\"\\n MELHORES MÉTRICAS:\")\n",
    "            print(f\"   • mAP@0.5: {best_map50:.4f}\")\n",
    "            print(f\"   • mAP@0.5:0.95: {best_map50_95:.4f}\")\n",
    "        \n",
    "        print(f\"\\n BLOCO 3 CONCLUÍDO COM SUCESSO!\")\n",
    "        print(\"    Próximo: BLOCO 4 - Modelos de Classificação\")\n",
    "        \n",
    "        return True, results_path\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n ERRO durante treinamento: {e}\")\n",
    "        print(\"   Verifique logs para mais detalhes\")\n",
    "        return False, None\n",
    "\n",
    "# 5. Execução\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "       \n",
    "    print(\" Para executar:\")\n",
    "    print(\"   success, model_path = train_yolo_detector()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-25T00:47:47.196204Z",
     "iopub.status.busy": "2025-06-25T00:47:47.195518Z",
     "iopub.status.idle": "2025-06-25T00:55:38.262180Z",
     "shell.execute_reply": "2025-06-25T00:55:38.261245Z",
     "shell.execute_reply.started": "2025-06-25T00:47:47.196177Z"
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "success, model_path = train_yolo_detector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-25T00:56:12.484326Z",
     "iopub.status.busy": "2025-06-25T00:56:12.483634Z",
     "iopub.status.idle": "2025-06-25T00:56:12.491517Z",
     "shell.execute_reply": "2025-06-25T00:56:12.490824Z",
     "shell.execute_reply.started": "2025-06-25T00:56:12.484301Z"
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Visualização do treino em outra célula (opcional):\n",
    "results_df = analyze_training_progress(\"/kaggle/working/yolo_training/cell_detector_v1\") #atenção para pasta que foi salva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-25T01:43:42.508445Z",
     "iopub.status.busy": "2025-06-25T01:43:42.507601Z",
     "iopub.status.idle": "2025-06-25T01:43:42.862377Z",
     "shell.execute_reply": "2025-06-25T01:43:42.861698Z",
     "shell.execute_reply.started": "2025-06-25T01:43:42.508421Z"
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Visualização de imagens individuais do treino\n",
    "img = Image.open('/kaggle/working/yolo_training/cell_detector_v1/F1_curve.png')\n",
    "plt.imshow(img)\n",
    "plt.axis('off')  # Hide axes\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-25T01:13:47.810663Z",
     "iopub.status.busy": "2025-06-25T01:13:47.810052Z",
     "iopub.status.idle": "2025-06-25T01:13:47.832992Z",
     "shell.execute_reply": "2025-06-25T01:13:47.832132Z",
     "shell.execute_reply.started": "2025-06-25T01:13:47.810641Z"
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Bloco 4: Visualização das Detecções YOLO\n",
    "# Análise visual do detector treinado\n",
    "\n",
    "print(\" Objetivo: Analisar visualmente as detecções do modelo treinado\")\n",
    "\n",
    "# 1. Configuração e Carregamento do Modelo\n",
    "\n",
    "# Paths\n",
    "MODEL_PATH = \"/kaggle/working/yolo_training/cell_detector_v1/weights/best.pt\" #atenção para pasta que foi salva\n",
    "DATASET_PATH = \"/kaggle/working/yolo_dataset\"\n",
    "TEST_IMAGES_PATH = f\"{DATASET_PATH}/images/test\"\n",
    "\n",
    "# Classes\n",
    "CLASS_NAMES = ['COM_corante', 'SEM_corante']\n",
    "CLASS_COLORS = {'COM_corante': 'blue', 'SEM_corante': 'red'}\n",
    "\n",
    "def load_trained_model():\n",
    "    \n",
    "    print(f\"\\n Carregando Modelo Treinado\")    \n",
    "    \n",
    "    \n",
    "    from ultralytics import YOLO\n",
    "    \n",
    "    # Verificar se modelo existe\n",
    "    if not Path(MODEL_PATH).exists():\n",
    "        print(f\" ERRO: Modelo não encontrado em {MODEL_PATH}\")\n",
    "        return None\n",
    "    \n",
    "    # Carregar modelo\n",
    "    model = YOLO(MODEL_PATH)\n",
    "    print(f\"    Modelo carregado: {MODEL_PATH}\")\n",
    "    print(f\"    Classes: {model.names}\")\n",
    "    \n",
    "    return model    \n",
    "\n",
    "def get_test_images(n_samples=8):\n",
    "    \n",
    "    print(f\"\\n Selecionando Imagens de Teste\")    \n",
    "    \n",
    "    test_images_dir = Path(TEST_IMAGES_PATH)    \n",
    "        \n",
    "    # Listar imagens\n",
    "    image_files = list(test_images_dir.glob(\"*.jpg\")) + list(test_images_dir.glob(\"*.jpeg\")) + list(test_images_dir.glob(\"*.png\"))\n",
    "    \n",
    "    if len(image_files) == 0:\n",
    "        print(f\" ERRO: Nenhuma imagem encontrada em {test_images_dir}\")\n",
    "        return []\n",
    "    \n",
    "    print(f\"    Total de imagens de teste: {len(image_files)}\")\n",
    "    \n",
    "    # Selecionar amostra aleatória\n",
    "    random.seed(42)  # Reprodutibilidade\n",
    "    if len(image_files) < n_samples:\n",
    "        n_samples = len(image_files)\n",
    "    \n",
    "    selected_images = random.sample(image_files, n_samples)\n",
    "    \n",
    "    print(f\"    Selecionadas: {len(selected_images)} imagens\")\n",
    "    for img in selected_images:\n",
    "        print(f\"      • {img.name}\")\n",
    "    \n",
    "    return selected_images\n",
    "\n",
    "# 2. Funções de Visualização\n",
    "\n",
    "def predict_and_visualize(model, image_path, conf_threshold=0.25):    \n",
    "    \n",
    "    # Carregar imagem\n",
    "    image = cv2.imread(str(image_path))\n",
    "    if image is None:\n",
    "        print(f\" Erro ao carregar: {image_path}\")\n",
    "        return None, None\n",
    "    \n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Predição\n",
    "    results = model(image_path, conf=conf_threshold, verbose=False)\n",
    "    \n",
    "    # Extrair informações das detecções\n",
    "    detections = []\n",
    "    if len(results) > 0 and results[0].boxes is not None:\n",
    "        boxes = results[0].boxes\n",
    "        \n",
    "        for i in range(len(boxes)):\n",
    "            box = boxes.xyxy[i].cpu().numpy()  # [x1, y1, x2, y2]\n",
    "            conf = boxes.conf[i].cpu().numpy()\n",
    "            cls = int(boxes.cls[i].cpu().numpy())\n",
    "            \n",
    "            detection = {\n",
    "                'bbox': box,\n",
    "                'confidence': conf,\n",
    "                'class_id': cls,\n",
    "                'class_name': CLASS_NAMES[cls]\n",
    "            }\n",
    "            detections.append(detection)\n",
    "    \n",
    "    return image_rgb, detections \n",
    "    \n",
    "def create_visualization_grid(model, image_paths, conf_threshold=0.25):\n",
    "    \n",
    "    print(f\"\\n Criando Visualizações\")    \n",
    "    \n",
    "    n_images = len(image_paths)    \n",
    "    \n",
    "    # Calcular grid\n",
    "    n_cols = min(4, n_images)\n",
    "    n_rows = (n_images + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, 5*n_rows))\n",
    "    if n_rows == 1:\n",
    "        axes = [axes] if n_cols == 1 else axes\n",
    "    else:\n",
    "        axes = axes.flatten()\n",
    "    \n",
    "    total_detections = 0\n",
    "    class_counts = {'COM_corante': 0, 'SEM_corante': 0}\n",
    "    \n",
    "    for idx, image_path in enumerate(image_paths):\n",
    "        print(f\"    Processando: {image_path.name}\")\n",
    "        \n",
    "        # Predição\n",
    "        image, detections = predict_and_visualize(model, image_path, conf_threshold)        \n",
    "        \n",
    "        # Plotar imagem\n",
    "        axes[idx].imshow(image)\n",
    "        \n",
    "        # Plotar detecções\n",
    "        detection_count = len(detections)\n",
    "        total_detections += detection_count\n",
    "        \n",
    "        for det in detections:\n",
    "            bbox = det['bbox']\n",
    "            conf = det['confidence']\n",
    "            class_name = det['class_name']\n",
    "            class_counts[class_name] += 1\n",
    "            \n",
    "            # Criar retângulo\n",
    "            x1, y1, x2, y2 = bbox\n",
    "            width = x2 - x1\n",
    "            height = y2 - y1\n",
    "            \n",
    "            rect = patches.Rectangle(\n",
    "                (x1, y1), width, height,\n",
    "                linewidth=2, \n",
    "                edgecolor=CLASS_COLORS[class_name], \n",
    "                facecolor='none', \n",
    "                alpha=0.8\n",
    "            )\n",
    "            axes[idx].add_patch(rect)\n",
    "            \n",
    "            # Label com confiança\n",
    "            label = f'{class_name}\\n{conf:.2f}' #editar para mostrar valor de confiança\n",
    "            axes[idx].text(x1, y1-10, label, \n",
    "                          color=CLASS_COLORS[class_name], \n",
    "                          fontsize=8, \n",
    "                          fontweight='bold',\n",
    "                          bbox=dict(boxstyle=\"round,pad=0.3\", \n",
    "                                   facecolor='white', \n",
    "                                   alpha=0.8))\n",
    "        \n",
    "        # Título com estatísticas\n",
    "        title = f'{image_path.name}\\n{detection_count} células detectadas'\n",
    "        axes[idx].set_title(title, fontsize=10)\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    # Ocultar axes vazios\n",
    "    for idx in range(len(image_paths), len(axes)):\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    # Título geral\n",
    "    main_title = f'Detecções YOLO - Confidence ≥ {conf_threshold}\\n'\n",
    "    main_title += f'Total: {total_detections} células | '\n",
    "    main_title += f'COM_corante: {class_counts[\"COM_corante\"]} | '\n",
    "    main_title += f'SEM_corante: {class_counts[\"SEM_corante\"]}'\n",
    "    \n",
    "    plt.suptitle(main_title, fontsize=16, fontweight='bold', y=0.98)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return total_detections, class_counts\n",
    "\n",
    "def analyze_detections_statistics(model, image_paths, conf_threshold=0.25):\n",
    "    \n",
    "    print(f\"\\n Análise das Detecções\")    \n",
    "    \n",
    "    all_detections = []\n",
    "    all_confidences = {'COM_corante': [], 'SEM_corante': []}\n",
    "    \n",
    "    for image_path in image_paths:\n",
    "        image, detections = predict_and_visualize(model, image_path, conf_threshold)\n",
    "        \n",
    "        if detections:\n",
    "            for det in detections:\n",
    "                all_detections.append(det)\n",
    "                all_confidences[det['class_name']].append(det['confidence'])\n",
    "    \n",
    "    if not all_detections:\n",
    "        print(\"    Nenhuma detecção encontrada\")\n",
    "        return\n",
    "    \n",
    "    # Estatísticas gerais\n",
    "    total_detections = len(all_detections)\n",
    "    class_counts = {'COM_corante': 0, 'SEM_corante': 0}\n",
    "    \n",
    "    for det in all_detections:\n",
    "        class_counts[det['class_name']] += 1\n",
    "    \n",
    "    print(f\"    Resumo Geral:\")\n",
    "    print(f\"      • Total de detecções: {total_detections}\")\n",
    "    print(f\"      • COM_corante: {class_counts['COM_corante']} ({class_counts['COM_corante']/total_detections*100:.1f}%)\")\n",
    "    print(f\"      • SEM_corante: {class_counts['SEM_corante']} ({class_counts['SEM_corante']/total_detections*100:.1f}%)\")\n",
    "    \n",
    "    # Estatísticas de confiança\n",
    "    print(f\"\\n    Análise de Confiança:\")\n",
    "    for class_name, confidences in all_confidences.items():\n",
    "        if confidences:\n",
    "            mean_conf = np.mean(confidences)\n",
    "            std_conf = np.std(confidences)\n",
    "            min_conf = np.min(confidences)\n",
    "            max_conf = np.max(confidences)\n",
    "            \n",
    "            print(f\"      {class_name}:\")\n",
    "            print(f\"         • Confiança média: {mean_conf:.3f} ± {std_conf:.3f}\")\n",
    "            print(f\"         • Intervalo: [{min_conf:.3f}, {max_conf:.3f}]\")\n",
    "    \n",
    "    # Plotar distribuição de confidências\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Histograma de confidências\n",
    "    for class_name, confidences in all_confidences.items():\n",
    "        if confidences:\n",
    "            axes[0].hist(confidences, alpha=0.7, label=class_name, \n",
    "                        color=CLASS_COLORS[class_name], bins=20)\n",
    "    \n",
    "    axes[0].set_title('Distribuição de Confidências')\n",
    "    axes[0].set_xlabel('Confiança')\n",
    "    axes[0].set_ylabel('Frequência')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Boxplot de confidências\n",
    "    conf_data = [all_confidences[cls] for cls in CLASS_NAMES if all_confidences[cls]]\n",
    "    conf_labels = [cls for cls in CLASS_NAMES if all_confidences[cls]]\n",
    "    \n",
    "    axes[1].boxplot(conf_data, labels=conf_labels)\n",
    "    axes[1].set_title('Boxplot - Confidências por Classe')\n",
    "    axes[1].set_ylabel('Confiança')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 3. Função Principal de Visualização\n",
    "\n",
    "def main_visualization(conf_threshold=0.25, n_samples=8):\n",
    "    \n",
    "    print(f\" Iniciando Visualização das Detecções\")    \n",
    "    \n",
    "    # 1. Carregar modelo\n",
    "    model = load_trained_model()    \n",
    "    \n",
    "    # 2. Selecionar imagens\n",
    "    image_paths = get_test_images(n_samples)    \n",
    "    \n",
    "    # 3. Criar visualizações\n",
    "    total_detections, class_counts = create_visualization_grid(\n",
    "        model, image_paths, conf_threshold\n",
    "    )\n",
    "    \n",
    "    # 4. Análise estatística\n",
    "    analyze_detections_statistics(model, image_paths, conf_threshold)\n",
    "    \n",
    "    # 5. Resumo final\n",
    "    print(f\"\\n Visualização Concluída\")\n",
    "    \n",
    "    print(f\"    Confiança mínima: {conf_threshold}\")\n",
    "    print(f\"    Total de detecções: {total_detections}\")\n",
    "    print(f\"    COM_corante: {class_counts['COM_corante']}\")\n",
    "    print(f\"    SEM_corante: {class_counts['SEM_corante']}\")    \n",
    "\n",
    "# 4. Execução\n",
    "\n",
    "if __name__ == \"__main__\":       \n",
    "    print(\" Para executar:\")\n",
    "    print(\"   main_visualization(conf_threshold=0.25, n_samples=8)\")    \n",
    "    print(\" Parâmetros:\")\n",
    "    print(\"   • conf_threshold: confiança mínima (0.1-0.9)\")\n",
    "    print(\"   • n_samples: número de imagens (1-20)\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-25T01:13:49.576201Z",
     "iopub.status.busy": "2025-06-25T01:13:49.575933Z",
     "iopub.status.idle": "2025-06-25T01:13:52.420988Z",
     "shell.execute_reply": "2025-06-25T01:13:52.420350Z",
     "shell.execute_reply.started": "2025-06-25T01:13:49.576182Z"
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "main_visualization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-25T02:19:12.520433Z",
     "iopub.status.busy": "2025-06-25T02:19:12.519838Z",
     "iopub.status.idle": "2025-06-25T02:19:12.540402Z",
     "shell.execute_reply": "2025-06-25T02:19:12.539651Z",
     "shell.execute_reply.started": "2025-06-25T02:19:12.520413Z"
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Bloco 5: Otimização YOLO \n",
    "# Estratégias para melhorar performance do detector YOLO\n",
    "\n",
    "print(\" Bloco 5: Otimização do Detector YOLO\")\n",
    "print(\" Objetivo: Melhorar o mAP@0.5 atual\")\n",
    "print(\" Estratégias: Fine-tuning avançado + Hyperparameter tuning\")\n",
    "\n",
    "# Configurações\n",
    "\n",
    "# Paths - AJUSTAR conforme sua estrutura\n",
    "CURRENT_MODEL = \"/kaggle/working/yolo_training/cell_detector_v1/weights/best.pt\"\n",
    "DATASET_PATH = \"/kaggle/working/yolo_dataset\"\n",
    "OUTPUT_PATH = \"/kaggle/working/yolo_optimization\"\n",
    "\n",
    "# Análise do Modelo Baseline\n",
    "\n",
    "def analyze_current_model():\n",
    "    \n",
    "    print(f\"\\n Análise do Modelo Baseline\")\n",
    "    \n",
    "    model = YOLO(CURRENT_MODEL)\n",
    "    \n",
    "    print(f\"    Modelo carregado: {CURRENT_MODEL}\") # Atualizar de acordo com performance do modelo\n",
    "    print(f\"    Performance baseline:\")\n",
    "    print(f\"      • mAP@0.5: 90.8%\")\n",
    "    print(f\"      • mAP@0.5:0.95: 58.0%\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Estratégia 1: Fine-Tuning Avançado\n",
    "\n",
    "def strategy_1_advanced_fine_tuning():\n",
    "        \n",
    "    print(f\"\\n Estratégia 1: Fine-Tuning Avançado\")\n",
    "    \n",
    "    # Configuração otimizada para fine-tuning\n",
    "    config = {\n",
    "        'model': 'yolov8s.pt',\n",
    "        'data': f\"{DATASET_PATH}/dataset.yaml\",\n",
    "        'epochs': 100,\n",
    "        'batch': 8,\n",
    "        'imgsz': 640,\n",
    "        'patience': 20,\n",
    "        'project': OUTPUT_PATH,\n",
    "        'name': 'advanced_fine_tune',\n",
    "        \n",
    "        # FINE-TUNING ESPECÍFICO\n",
    "        'lr0': 0.0001,        # Learning rate muito baixo\n",
    "        'lrf': 0.01,          # Decay menor\n",
    "        'weight_decay': 0.001, # Regularização aumentada\n",
    "        'dropout': 0.1,       # Dropout para evitar overfitting\n",
    "        'warmup_epochs': 5,\n",
    "        \n",
    "        # AUGMENTATION PARA MICROSCOPIA\n",
    "        'degrees': 5.0,       # Rotação reduzida\n",
    "        'translate': 0.05,    # Translação mínima\n",
    "        'scale': 0.2,         # Scale reduzido\n",
    "        'flipud': 0.0,        # Sem flip vertical\n",
    "        'fliplr': 0.3,        # Flip horizontal reduzido\n",
    "        'mosaic': 0.5,        # Mosaic reduzido\n",
    "        'hsv_h': 0.01,        # Preservar cores do corante\n",
    "        'hsv_s': 0.3,\n",
    "        'hsv_v': 0.2,\n",
    "        \n",
    "        # LOSS WEIGHTS\n",
    "        'box': 7.5,\n",
    "        'cls': 0.75,          # Foco na classificação\n",
    "        \n",
    "        # OTIMIZAÇÕES\n",
    "        'optimizer': 'AdamW',\n",
    "        'cos_lr': True,\n",
    "        'amp': True,\n",
    "        'seed': 42,\n",
    "        'deterministic': True,\n",
    "        'verbose': True\n",
    "    }\n",
    "    \n",
    "    print(f\"    Configuração:\")\n",
    "    print(f\"      • Learning rate: {config['lr0']} (muito baixo)\")\n",
    "    print(f\"      • Regularização: weight_decay={config['weight_decay']}, dropout={config['dropout']}\")\n",
    "    print(f\"      • Augmentation: Conservador para microscopia\")\n",
    "    print(f\"      • Class loss: {config['cls']} (aumentado)\")\n",
    "    \n",
    "    print(f\"\\n    Iniciando fine-tuning avançado...\")\n",
    "    model = YOLO('yolov8s.pt')\n",
    "    results = model.train(**config)\n",
    "    \n",
    "    print(f\"     Fine-tuning avançado concluído.\")\n",
    "    return results, f\"{OUTPUT_PATH}/advanced_fine_tune\"\n",
    "\n",
    "# Estratégia 2: Otimização de Hiperparâmetros\n",
    "\n",
    "def strategy_2_hyperparameter_optimization():\n",
    "    \n",
    "    print(f\"\\n Estratégia 2: Otimização de Hiperparâmetros\")\n",
    "    \n",
    "    # 3 sub-estratégias para testar\n",
    "    configs = [\n",
    "        {\n",
    "            'name': 'high_class_weight',\n",
    "            'description': 'Peso maior para classificação',\n",
    "            'config': {\n",
    "                'cls': 1.0,    # Foco na classificação COM vs SEM\n",
    "                'box': 7.0,    # Peso menor para detecção\n",
    "                'epochs': 50\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'name': 'high_regularization', \n",
    "            'description': 'Regularização aumentada',\n",
    "            'config': {\n",
    "                'weight_decay': 0.001,  # Regularização forte\n",
    "                'dropout': 0.2,         # Dropout alto\n",
    "                'warmup_epochs': 10,    # Warmup longo\n",
    "                'epochs': 50\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'name': 'minimal_augmentation',\n",
    "            'description': 'Augmentation mínimo',\n",
    "            'config': {\n",
    "                'degrees': 2.0,     # Rotação mínima\n",
    "                'translate': 0.02,  # Translação mínima\n",
    "                'scale': 0.1,       # Scale mínimo\n",
    "                'mosaic': 0.2,      # Mosaic reduzido\n",
    "                'mixup': 0.0,       # Sem mixup\n",
    "                'epochs': 50\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for config_info in configs:\n",
    "        name = config_info['name']\n",
    "        description = config_info['description']\n",
    "        specific_config = config_info['config']\n",
    "        \n",
    "        print(f\"\\n     Testando: {description}\")\n",
    "        print(f\"        Config: {name}\")\n",
    "        \n",
    "        # Configuração base comum\n",
    "        base_config = {\n",
    "            'data': f\"{DATASET_PATH}/dataset.yaml\",\n",
    "            'batch': 8,\n",
    "            'imgsz': 640,\n",
    "            'patience': 10,\n",
    "            'project': OUTPUT_PATH,\n",
    "            'name': f'hyperparam_{name}',\n",
    "            'seed': 42,\n",
    "            'deterministic': True,\n",
    "            'verbose': False\n",
    "        }\n",
    "        \n",
    "        # Combinar configurações\n",
    "        full_config = {**base_config, **specific_config}\n",
    "        \n",
    "        # Treinar modelo\n",
    "        model = YOLO('yolov8s.pt')\n",
    "        result = model.train(**full_config)\n",
    "        \n",
    "        results[name] = {\n",
    "            'description': description,\n",
    "            'config': specific_config,\n",
    "            'result_path': f\"{OUTPUT_PATH}/hyperparam_{name}\",\n",
    "            'success': True\n",
    "        }\n",
    "        \n",
    "        print(f\"         Concluído: {name}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Comparação de Resultados\n",
    "\n",
    "def compare_optimization_results(original_map=0.908): #definir de acordo com o modelo\n",
    "    \n",
    "    print(f\"\\n Comparação de Resultados de Otimização\")\n",
    "    \n",
    "    results_summary = []\n",
    "    \n",
    "    # 1. Resultado baseline\n",
    "    results_summary.append({\n",
    "        'Modelo': 'YOLO Original',\n",
    "        'mAP@0.5': f\"{original_map:.3f}\",\n",
    "        'Estratégia': 'Baseline',        \n",
    "        'Status': 'Referência'\n",
    "    })\n",
    "    \n",
    "    # 2. Fine-tuning avançado\n",
    "    fine_tune_path = Path(f\"{OUTPUT_PATH}/advanced_fine_tune\")\n",
    "    if fine_tune_path.exists():\n",
    "        results_file = fine_tune_path / \"results.csv\"\n",
    "        if results_file.exists():\n",
    "            try:\n",
    "                df = pd.read_csv(results_file)\n",
    "                best_map = df['metrics/mAP50(B)'].max()\n",
    "                \n",
    "                results_summary.append({\n",
    "                    'Modelo': 'Fine-tuning Avançado',\n",
    "                    'mAP@0.5': f\"{best_map:.3f}\",\n",
    "                    'Estratégia': 'Learning rate baixo + regularização',                    \n",
    "                    'Status': 'Melhorado' if best_map > original_map else 'Similar'\n",
    "                })\n",
    "            except:\n",
    "                print(\"    Erro ao ler resultados do fine-tuning\")\n",
    "    \n",
    "    # 3. Hyperparameter optimization (3 sub-estratégias)\n",
    "    hyperparam_configs = ['high_class_weight', 'high_regularization', 'minimal_augmentation']\n",
    "    strategy_names = {\n",
    "        'high_class_weight': 'High Class Weight',\n",
    "        'high_regularization': 'High Regularization', \n",
    "        'minimal_augmentation': 'Minimal Augmentation'\n",
    "    }\n",
    "    \n",
    "    for config_name in hyperparam_configs:\n",
    "        config_path = Path(f\"{OUTPUT_PATH}/hyperparam_{config_name}\")\n",
    "        if config_path.exists():\n",
    "            results_file = config_path / \"results.csv\"\n",
    "            if results_file.exists():\n",
    "                try:\n",
    "                    df = pd.read_csv(results_file)\n",
    "                    best_map = df['metrics/mAP50(B)'].max()\n",
    "                    \n",
    "                    results_summary.append({\n",
    "                        'Modelo': f'Hyperparam {config_name}',\n",
    "                        'mAP@0.5': f\"{best_map:.3f}\",\n",
    "                        'Estratégia': strategy_names[config_name],                        \n",
    "                        'Status': 'Melhorado' if best_map > original_map else 'Similar'\n",
    "                    })\n",
    "                except:\n",
    "                    print(f\"     Erro ao ler resultados de {config_name}\")\n",
    "    \n",
    "    # Criar e exibir tabela comparativa\n",
    "    comparison_df = pd.DataFrame(results_summary)\n",
    "    print(f\"\\n{comparison_df.to_string(index=False)}\")\n",
    "    \n",
    "    # Identificar melhor resultado\n",
    "    if len(results_summary) > 1:\n",
    "        best_idx = 0\n",
    "        best_map = original_map\n",
    "        \n",
    "        for i, result in enumerate(results_summary[1:], 1):\n",
    "            \n",
    "            current_map = float(result['mAP@0.5'])\n",
    "            if current_map > best_map:\n",
    "                best_map = current_map\n",
    "                best_idx = i            \n",
    "        \n",
    "        if best_idx > 0:\n",
    "            improvement = ((best_map - original_map) / original_map) * 100\n",
    "            print(f\"\\n Melhor Resultado:\")\n",
    "            print(f\"   • Modelo: {results_summary[best_idx]['Modelo']}\")\n",
    "            print(f\"   • mAP@0.5: {best_map:.3f}\")\n",
    "            print(f\"   • Melhoria: {improvement:.1f}%\")\n",
    "            print(f\"   • Estratégia: {results_summary[best_idx]['Estratégia']}\")\n",
    "        else:\n",
    "            print(f\"\\n Resultado:\")\n",
    "            print(f\"   • Modelo original mantém melhor performance\")\n",
    "            print(f\"   • mAP@0.5: {original_map:.3f} (baseline)\")\n",
    "    \n",
    "    return comparison_df\n",
    "\n",
    "# Função Principal\n",
    "\n",
    "def optimize_yolo_detector():\n",
    "    \n",
    "    print(f\"\\n Ininciando Otimização\")\n",
    "    \n",
    "    # Criar diretório de saída\n",
    "    Path(OUTPUT_PATH).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # ETAPA 1: Análise do modelo baseline\n",
    "    print(f\"\\n\")\n",
    "    print(f\" Etapa 1: Análise do Modelo Baseline\")\n",
    "    print(f\"\\n\")\n",
    "    current_model = analyze_current_model()\n",
    "    \n",
    "    # ETAPA 2: Estratégia 1 - Fine-tuning avançado \n",
    "    print(f\"\\n\")\n",
    "    print(f\" Etapa 2: Estratégia 1 - Fine-Tuning\")\n",
    "    print(f\"\\n\")\n",
    "    fine_tune_results, fine_tune_path = strategy_1_advanced_fine_tuning()\n",
    "    \n",
    "    # ETAPA 3: Estratégia 2 - Hiperparameter optimization\n",
    "    print(f\"\\n\")\n",
    "    print(f\" Etapa 3: Estratégia 2 - Hiperparameter Optimization\")\n",
    "    print(f\"\\n\")\n",
    "    hyperparam_results = strategy_2_hyperparameter_optimization()\n",
    "    \n",
    "    # ETAPA 4: Comparação final\n",
    "    print(f\"\\n\")\n",
    "    print(f\" Etapa 4: Comparação Final de Resultados\")\n",
    "    print(f\"\\n\")\n",
    "    comparison_df = compare_optimization_results()\n",
    "    \n",
    "    # Resultado final\n",
    "    print(f\"\\n\")\n",
    "    print(f\"  Otimização Finalizada!\")\n",
    "    print(f\"\\n\")\n",
    "    print(f\"     Todas as estratégias testadas\")\n",
    "    print(f\"     Relatório de comparação gerado\")\n",
    "    print(f\"     Melhor modelo identificado\")\n",
    "    print(f\"     Resultados salvos em: {OUTPUT_PATH}\")\n",
    "    \n",
    "    return {\n",
    "        'fine_tune_results': fine_tune_results,\n",
    "        'hyperparam_results': hyperparam_results,\n",
    "        'comparison': comparison_df,\n",
    "        'output_path': OUTPUT_PATH\n",
    "    }\n",
    "\n",
    "# Execução\n",
    "\n",
    "if __name__ == \"__main__\":    \n",
    "    \n",
    "    print(f\"\\n Estratégias Implementadas:\")\n",
    "    print(f\"    Baseline: Modelo original (referência)\")\n",
    "    print(f\"    Estratégia 1: Fine-tuning Avançado\")\n",
    "    print(f\"    Estratégia 2: Hyperparameter Optimization\")\n",
    "    print(f\"      ├── High Class Weight\")\n",
    "    print(f\"      ├── High Regularization\") \n",
    "    print(f\"      └── Minimal Augmentation\")\n",
    "    print(f\"    Comparação e Análise Final\")\n",
    "    \n",
    "    print(f\"\\n Para Executar:\")\n",
    "    print(f\"   results = optimize_yolo_detector()\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-25T02:19:31.602056Z",
     "iopub.status.busy": "2025-06-25T02:19:31.601348Z",
     "iopub.status.idle": "2025-06-25T02:36:33.518319Z",
     "shell.execute_reply": "2025-06-25T02:36:33.517389Z",
     "shell.execute_reply.started": "2025-06-25T02:19:31.602030Z"
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Executar otimização\n",
    "results = optimize_yolo_detector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-25T03:28:40.906215Z",
     "iopub.status.busy": "2025-06-25T03:28:40.905347Z",
     "iopub.status.idle": "2025-06-25T03:28:40.948356Z",
     "shell.execute_reply": "2025-06-25T03:28:40.947420Z",
     "shell.execute_reply.started": "2025-06-25T03:28:40.906191Z"
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Bloco 6: Threshold Optimization para Todos os 5 Modelos\n",
    "# Otimiza threshold individual para cada modelo treinado\n",
    "\n",
    "print(\" Bloco 6: Otimização de Threshold para Todos os Modelos\")\n",
    "print(\" Objetivo: Encontrar threshold ótimo individual\")\n",
    "print(\" Estratégia: Maximizar F1-Score por modelo\")\n",
    "\n",
    "# Configurações\n",
    "\n",
    "# Configuração dos 5 Modelos\n",
    "MODELS_CONFIG = {\n",
    "    'Baseline': {\n",
    "        'path': '/kaggle/working/yolo_training/cell_detector_v1/weights/best.pt', \n",
    "        'description': 'Modelo original de referência'\n",
    "    },\n",
    "    'Fine-tuning': {\n",
    "        'path': '/kaggle/working/yolo_optimization/advanced_fine_tune/weights/best.pt', \n",
    "        'description': 'Fine-tuning com learning rate baixo'\n",
    "    },\n",
    "    'High Class Weight': {\n",
    "        'path': '/kaggle/working/yolo_optimization/hyperparam_high_class_weight/weights/best.pt',\n",
    "        'description': 'Peso aumentado para classificação'\n",
    "    },\n",
    "    'High Regularization': {\n",
    "        'path': '/kaggle/working/yolo_optimization/hyperparam_high_regularization/weights/best.pt',\n",
    "        'description': 'Regularização aumentada'\n",
    "    },\n",
    "    'Minimal Augmentation': {\n",
    "        'path': '/kaggle/working/yolo_optimization/hyperparam_minimal_augmentation/weights/best.pt',\n",
    "        'description': 'Augmentation mínimo'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Dataset e configurações\n",
    "DATASET_PATH = \"/kaggle/working/yolo_dataset\"\n",
    "VALIDATION_IMAGES_PATH = f\"{DATASET_PATH}/images/valid\"\n",
    "VALIDATION_LABELS_PATH = f\"{DATASET_PATH}/labels/valid\"\n",
    "\n",
    "# Classes do projeto\n",
    "CLASS_NAMES = ['COM_corante', 'SEM_corante']\n",
    "\n",
    "# Parâmetros da otimização\n",
    "THRESHOLD_RANGE = np.arange(0.10, 0.90, 0.05)  # 0.10 até 0.85 com passo 0.05\n",
    "IoU_THRESHOLD = 0.5  # Para cálculo de True Positive/False Positive\n",
    "\n",
    "print(f\" Configuração:\")\n",
    "print(f\"   • {len(MODELS_CONFIG)} modelos para otimizar\")\n",
    "print(f\"   • {len(THRESHOLD_RANGE)} thresholds testados: {THRESHOLD_RANGE[0]:.2f} a {THRESHOLD_RANGE[-1]:.2f}\")\n",
    "print(f\"   • IoU threshold: {IoU_THRESHOLD}\")\n",
    "print(f\"   • Classes: {CLASS_NAMES}\")\n",
    "\n",
    "# Funções Auxiliares\n",
    "\n",
    "def load_ground_truth_annotations(label_file):\n",
    "    \n",
    "    annotations = []\n",
    "    if Path(label_file).exists():\n",
    "        with open(label_file, 'r') as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) >= 5:\n",
    "                    class_id = int(parts[0])\n",
    "                    x_center = float(parts[1])\n",
    "                    y_center = float(parts[2])\n",
    "                    width = float(parts[3])\n",
    "                    height = float(parts[4])\n",
    "                    \n",
    "                    annotations.append({\n",
    "                        'class_id': class_id,\n",
    "                        'x_center': x_center,\n",
    "                        'y_center': y_center,\n",
    "                        'width': width,\n",
    "                        'height': height\n",
    "                    })\n",
    "    return annotations\n",
    "\n",
    "def convert_yolo_to_xyxy(annotation, img_width, img_height):\n",
    "    \n",
    "    x_center = annotation['x_center'] * img_width\n",
    "    y_center = annotation['y_center'] * img_height\n",
    "    width = annotation['width'] * img_width\n",
    "    height = annotation['height'] * img_height\n",
    "    \n",
    "    x1 = x_center - width / 2\n",
    "    y1 = y_center - height / 2\n",
    "    x2 = x_center + width / 2\n",
    "    y2 = y_center + height / 2\n",
    "    \n",
    "    return [x1, y1, x2, y2]\n",
    "\n",
    "def calculate_iou(box1, box2):\n",
    "    \n",
    "    x1 = max(box1[0], box2[0])\n",
    "    y1 = max(box1[1], box2[1])\n",
    "    x2 = min(box1[2], box2[2])\n",
    "    y2 = min(box1[3], box2[3])\n",
    "    \n",
    "    if x2 <= x1 or y2 <= y1:\n",
    "        return 0.0\n",
    "    \n",
    "    intersection = (x2 - x1) * (y2 - y1)\n",
    "    area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "    area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "    union = area1 + area2 - intersection\n",
    "    \n",
    "    return intersection / union if union > 0 else 0.0\n",
    "\n",
    "def calculate_detection_metrics(all_detections, all_ground_truths):\n",
    "   # Calcula métricas de detecção: precision, recall, F1 geral e por classe\n",
    "    metrics_per_class = {}\n",
    "    \n",
    "    # Inicializar contadores por classe\n",
    "    for class_name in CLASS_NAMES:\n",
    "        metrics_per_class[class_name] = {\n",
    "            'tp': 0, 'fp': 0, 'fn': 0,\n",
    "            'precision': 0.0, 'recall': 0.0, 'f1': 0.0\n",
    "        }\n",
    "    \n",
    "    # Processar cada imagem\n",
    "    for detections, ground_truths in zip(all_detections, all_ground_truths):\n",
    "        # Organizar por classe\n",
    "        gt_by_class = defaultdict(list)\n",
    "        det_by_class = defaultdict(list)\n",
    "        \n",
    "        for gt in ground_truths:\n",
    "            gt_by_class[gt['class_name']].append(gt)\n",
    "        \n",
    "        for det in detections:\n",
    "            det_by_class[det['class_name']].append(det)\n",
    "        \n",
    "        # Calcular TP/FP/FN para cada classe\n",
    "        for class_name in CLASS_NAMES:\n",
    "            gt_boxes = gt_by_class[class_name]\n",
    "            det_boxes = det_by_class[class_name]\n",
    "            \n",
    "            # Marcar ground truths matched\n",
    "            gt_matched = [False] * len(gt_boxes)\n",
    "            \n",
    "            # Para cada detecção, encontrar melhor match\n",
    "            for det in det_boxes:\n",
    "                best_iou = 0\n",
    "                best_gt_idx = -1\n",
    "                \n",
    "                for gt_idx, gt in enumerate(gt_boxes):\n",
    "                    if gt_matched[gt_idx]:\n",
    "                        continue\n",
    "                    \n",
    "                    iou = calculate_iou(det['bbox'], gt['bbox'])\n",
    "                    if iou > best_iou:\n",
    "                        best_iou = iou\n",
    "                        best_gt_idx = gt_idx\n",
    "                \n",
    "                # Classificar como TP ou FP\n",
    "                if best_iou >= IoU_THRESHOLD:\n",
    "                    metrics_per_class[class_name]['tp'] += 1\n",
    "                    gt_matched[best_gt_idx] = True\n",
    "                else:\n",
    "                    metrics_per_class[class_name]['fp'] += 1\n",
    "            \n",
    "            # Contar FN (ground truths não matched)\n",
    "            metrics_per_class[class_name]['fn'] += sum(1 for matched in gt_matched if not matched)\n",
    "    \n",
    "    # Calcular precision, recall, F1 para cada classe\n",
    "    for class_name in CLASS_NAMES:\n",
    "        tp = metrics_per_class[class_name]['tp']\n",
    "        fp = metrics_per_class[class_name]['fp']\n",
    "        fn = metrics_per_class[class_name]['fn']\n",
    "        \n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "        \n",
    "        metrics_per_class[class_name].update({\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1\n",
    "        })\n",
    "    \n",
    "    # Calcular métricas gerais (macro average)\n",
    "    total_tp = sum(metrics_per_class[cls]['tp'] for cls in CLASS_NAMES)\n",
    "    total_fp = sum(metrics_per_class[cls]['fp'] for cls in CLASS_NAMES)\n",
    "    total_fn = sum(metrics_per_class[cls]['fn'] for cls in CLASS_NAMES)\n",
    "    \n",
    "    overall_precision = total_tp / (total_tp + total_fp) if (total_tp + total_fp) > 0 else 0.0\n",
    "    overall_recall = total_tp / (total_tp + total_fn) if (total_tp + total_fn) > 0 else 0.0\n",
    "    overall_f1 = 2 * overall_precision * overall_recall / (overall_precision + overall_recall) if (overall_precision + overall_recall) > 0 else 0.0\n",
    "    \n",
    "    return {\n",
    "        'per_class': metrics_per_class,\n",
    "        'overall': {\n",
    "            'precision': overall_precision,\n",
    "            'recall': overall_recall,\n",
    "            'f1': overall_f1,\n",
    "            'tp': total_tp,\n",
    "            'fp': total_fp,\n",
    "            'fn': total_fn\n",
    "        }\n",
    "    }\n",
    "\n",
    "def get_validation_image_pairs():\n",
    "    \n",
    "    validation_pairs = []\n",
    "    \n",
    "    img_dir = Path(VALIDATION_IMAGES_PATH)\n",
    "    label_dir = Path(VALIDATION_LABELS_PATH)  \n",
    "    \n",
    "    # Buscar todas as imagens\n",
    "    img_extensions = ['.jpg', '.jpeg', '.png', '.bmp']\n",
    "    for img_file in img_dir.iterdir():\n",
    "        if img_file.suffix.lower() in img_extensions:\n",
    "            # Procurar arquivo de label correspondente\n",
    "            label_file = label_dir / f\"{img_file.stem}.txt\"\n",
    "            if label_file.exists():\n",
    "                validation_pairs.append((str(img_file), str(label_file)))\n",
    "    \n",
    "    print(f\" Encontradas {len(validation_pairs)} imagens de validação com anotações\")\n",
    "    return validation_pairs\n",
    "\n",
    "def evaluate_single_threshold(model, validation_pairs, threshold, model_name=\"\"):\n",
    "    \n",
    "    all_detections = []\n",
    "    all_ground_truths = []\n",
    "    \n",
    "    for img_path, label_path in validation_pairs:\n",
    "        \n",
    "        # Fazer predição\n",
    "        results = model(img_path, conf=threshold, verbose=False)[0]\n",
    "        img = Image.open(img_path)\n",
    "        img_width, img_height = img.size\n",
    "        \n",
    "        # Carregar ground truth\n",
    "        gt_annotations = load_ground_truth_annotations(label_path)\n",
    "        \n",
    "        # Converter predições para formato padrão\n",
    "        detections = []\n",
    "        if results.boxes is not None:\n",
    "            for i in range(len(results.boxes)):\n",
    "                box = results.boxes.xyxy[i].cpu().numpy()\n",
    "                conf = results.boxes.conf[i].cpu().numpy()\n",
    "                cls = int(results.boxes.cls[i].cpu().numpy())\n",
    "                \n",
    "                detections.append({\n",
    "                    'bbox': box,\n",
    "                    'confidence': conf,\n",
    "                    'class_id': cls,\n",
    "                    'class_name': CLASS_NAMES[cls]\n",
    "                })\n",
    "        \n",
    "        # Converter ground truth para formato padrão\n",
    "        ground_truths = []\n",
    "        for ann in gt_annotations:\n",
    "            bbox = convert_yolo_to_xyxy(ann, img_width, img_height)\n",
    "            ground_truths.append({\n",
    "                'bbox': bbox,\n",
    "                'class_id': ann['class_id'],\n",
    "                'class_name': CLASS_NAMES[ann['class_id']]\n",
    "            })\n",
    "        \n",
    "        all_detections.append(detections)\n",
    "        all_ground_truths.append(ground_truths)            \n",
    "        \n",
    "    \n",
    "    # Calcular métricas\n",
    "    metrics = calculate_detection_metrics(all_detections, all_ground_truths)\n",
    "    \n",
    "    return {\n",
    "        'threshold': threshold,\n",
    "        'metrics': metrics,\n",
    "        'total_detections': sum(len(dets) for dets in all_detections),\n",
    "        'total_ground_truth': sum(len(gts) for gts in all_ground_truths),\n",
    "        **metrics\n",
    "    }\n",
    "\n",
    "# Otimização para um Modelo\n",
    "\n",
    "\n",
    "def optimize_single_model(model_name, model_path, validation_pairs):\n",
    "    \n",
    "    print(f\"\\n Otimizando: {model_name}\")\n",
    "    print(f\"   Modelo: {model_path}\")\n",
    "    print(f\"   Descrição: {MODELS_CONFIG[model_name]['description']}\")\n",
    "    \n",
    "    # Carregar modelo    \n",
    "    model = YOLO(model_path)    \n",
    "    \n",
    "    # Testar todos os thresholds\n",
    "    print(f\"    Testando {len(THRESHOLD_RANGE)} thresholds...\")\n",
    "    \n",
    "    results = []\n",
    "    for i, threshold in enumerate(THRESHOLD_RANGE):\n",
    "        print(f\"      [{i+1:2d}/{len(THRESHOLD_RANGE)}] Threshold {threshold:.2f}...\", end=\"\")\n",
    "        \n",
    "        result = evaluate_single_threshold(model, validation_pairs, threshold, model_name)\n",
    "        results.append(result)\n",
    "        \n",
    "        print(f\" F1: {result['overall']['f1']:.3f}\")\n",
    "    \n",
    "    # Converter para DataFrame\n",
    "    df_data = []\n",
    "    for result in results:\n",
    "        row = {\n",
    "            'threshold': result['threshold'],\n",
    "            'precision': result['overall']['precision'],\n",
    "            'recall': result['overall']['recall'],\n",
    "            'f1': result['overall']['f1'],\n",
    "            'total_detections': result['total_detections'],\n",
    "            'total_ground_truth': result['total_ground_truth']\n",
    "        }\n",
    "        \n",
    "        # Adicionar métricas por classe\n",
    "        for cls in CLASS_NAMES:\n",
    "            row[f'{cls}_precision'] = result['per_class'][cls]['precision']\n",
    "            row[f'{cls}_recall'] = result['per_class'][cls]['recall']\n",
    "            row[f'{cls}_f1'] = result['per_class'][cls]['f1']\n",
    "        \n",
    "        df_data.append(row)\n",
    "    \n",
    "    df = pd.DataFrame(df_data)\n",
    "    \n",
    "    # Encontrar threshold ótimo\n",
    "    best_idx = df['f1'].idxmax()\n",
    "    best_threshold = df.loc[best_idx, 'threshold']\n",
    "    best_f1 = df.loc[best_idx, 'f1']\n",
    "    best_precision = df.loc[best_idx, 'precision']\n",
    "    best_recall = df.loc[best_idx, 'recall']\n",
    "    \n",
    "    print(f\"\\n    Resultado Ótimo:\")\n",
    "    print(f\"      • Threshold: {best_threshold:.2f}\")\n",
    "    print(f\"      • F1-Score: {best_f1:.3f}\")\n",
    "    print(f\"      • Precision: {best_precision:.3f}\")\n",
    "    print(f\"      • Recall: {best_recall:.3f}\")\n",
    "    \n",
    "    return {\n",
    "        'model_name': model_name,\n",
    "        'model_path': model_path,\n",
    "        'best_threshold': best_threshold,\n",
    "        'best_f1': best_f1,\n",
    "        'best_precision': best_precision,\n",
    "        'best_recall': best_recall,\n",
    "        'all_results': df,\n",
    "        'optimization_data': results\n",
    "    }\n",
    "\n",
    "# Função Principal\n",
    "\n",
    "def optimize_all_models_thresholds():\n",
    "    \n",
    "    print(f\"\\n Iniciando Otimização para Todos os Modelos\")    \n",
    "    \n",
    "    # Obter dados de validação\n",
    "    validation_pairs = get_validation_image_pairs()    \n",
    "    \n",
    "    # Otimizar cada modelo\n",
    "    optimization_results = {}\n",
    "    \n",
    "    for model_name, config in MODELS_CONFIG.items():\n",
    "        result = optimize_single_model(model_name, config['path'], validation_pairs)\n",
    "        if result:\n",
    "            optimization_results[model_name] = result\n",
    "    \n",
    "    # Análise comparativa\n",
    "    print(f\"\\n Análise Comparativa dos Thresholds Ótimos\")    \n",
    "    \n",
    "    # Tabela comparativa\n",
    "    comparison_data = []\n",
    "    for model_name, result in optimization_results.items():\n",
    "        comparison_data.append({\n",
    "            'Modelo': model_name,\n",
    "            'Threshold Ótimo': f\"{result['best_threshold']:.2f}\",\n",
    "            'F1-Score': f\"{result['best_f1']:.3f}\",\n",
    "            'Precision': f\"{result['best_precision']:.3f}\",\n",
    "            'Recall': f\"{result['best_recall']:.3f}\"\n",
    "        })\n",
    "    \n",
    "    df_comparison = pd.DataFrame(comparison_data)\n",
    "    df_comparison = df_comparison.sort_values('F1-Score', ascending=False)\n",
    "    \n",
    "    print(\" Ranking dos Resultados (por F1-Score):\")    \n",
    "    print(df_comparison.to_string(index=False))\n",
    "    \n",
    "    # Melhor modelo geral\n",
    "    best_model_name = df_comparison.iloc[0]['Modelo']\n",
    "    best_model_result = optimization_results[best_model_name]\n",
    "    \n",
    "    print(f\"\\n Melhor Modelo Geral:\")\n",
    "    print(f\"   • Modelo: {best_model_name}\")\n",
    "    print(f\"   • Threshold ótimo: {best_model_result['best_threshold']:.2f}\")\n",
    "    print(f\"   • F1-Score: {best_model_result['best_f1']:.3f}\")\n",
    "    print(f\"   • Descrição: {MODELS_CONFIG[best_model_name]['description']}\")\n",
    "    \n",
    "    \n",
    "    print(f\"\\n Threshold Otimizados:\")    \n",
    "    print(\"OPTIMIZED_THRESHOLDS = {\")\n",
    "    for model_name, result in optimization_results.items():\n",
    "        print(f\"    '{model_name}': {result['best_threshold']:.2f},\")\n",
    "    print(\"}\")\n",
    "    \n",
    "    # Visualização comparativa\n",
    "    print(f\"\\n Gerando visualização comparativa...\")\n",
    "    create_comparison_visualization(optimization_results)\n",
    "    \n",
    "    return optimization_results, df_comparison, best_model_name\n",
    "\n",
    "def create_comparison_visualization(optimization_results):\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Subplot 1: Curvas F1 de todos os modelos\n",
    "    plt.subplot(2, 3, 1)\n",
    "    colors = ['blue', 'red', 'green', 'orange', 'purple']\n",
    "    \n",
    "    for i, (model_name, result) in enumerate(optimization_results.items()):\n",
    "        df = result['all_results']\n",
    "        plt.plot(df['threshold'], df['f1'], \n",
    "                label=model_name, color=colors[i % len(colors)], linewidth=2)\n",
    "        \n",
    "        # Marcar ponto ótimo\n",
    "        plt.scatter(result['best_threshold'], result['best_f1'], \n",
    "                   color=colors[i % len(colors)], s=100, zorder=5)\n",
    "    \n",
    "    plt.title('Curvas F1-Score vs Threshold')\n",
    "    plt.xlabel('Threshold de Confiança')\n",
    "    plt.ylabel('F1-Score')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Subplot 2: Comparison de thresholds ótimos\n",
    "    plt.subplot(2, 3, 2)\n",
    "    models = list(optimization_results.keys())\n",
    "    thresholds = [optimization_results[m]['best_threshold'] for m in models]\n",
    "    f1_scores = [optimization_results[m]['best_f1'] for m in models]\n",
    "    \n",
    "    bars = plt.bar(range(len(models)), thresholds, color=colors[:len(models)])\n",
    "    plt.title('Thresholds Ótimos por Modelo')\n",
    "    plt.xlabel('Modelos')\n",
    "    plt.ylabel('Threshold Ótimo')\n",
    "    plt.xticks(range(len(models)), models, rotation=45)\n",
    "    \n",
    "    # Adiciona valores nas barras\n",
    "    for i, (bar, thresh) in enumerate(zip(bars, thresholds)):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                f'{thresh:.2f}', ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Subplot 3: F1-Scores máximos\n",
    "    plt.subplot(2, 3, 3)\n",
    "    bars = plt.bar(range(len(models)), f1_scores, color=colors[:len(models)])\n",
    "    plt.title('F1-Score Máximo por Modelo')\n",
    "    plt.xlabel('Modelos')\n",
    "    plt.ylabel('F1-Score Máximo')\n",
    "    plt.xticks(range(len(models)), models, rotation=45)\n",
    "    \n",
    "    # Adicionar valores nas barras\n",
    "    for i, (bar, f1) in enumerate(zip(bars, f1_scores)):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005,\n",
    "                f'{f1:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    # Subplots 4-6: Precision e Recall curves para top 3 modelos\n",
    "    top_3_models = sorted(optimization_results.items(), \n",
    "                         key=lambda x: x[1]['best_f1'], reverse=True)[:3]\n",
    "    \n",
    "    for i, (model_name, result) in enumerate(top_3_models):\n",
    "        plt.subplot(2, 3, 4 + i)\n",
    "        df = result['all_results']\n",
    "        \n",
    "        plt.plot(df['threshold'], df['precision'], 'b-', label='Precision', linewidth=2)\n",
    "        plt.plot(df['threshold'], df['recall'], 'r-', label='Recall', linewidth=2)\n",
    "        plt.plot(df['threshold'], df['f1'], 'g-', label='F1-Score', linewidth=2)\n",
    "        plt.axvline(result['best_threshold'], color='green', linestyle='--', \n",
    "                   alpha=0.7, label=f'Ótimo ({result[\"best_threshold\"]:.2f})')\n",
    "        \n",
    "        plt.title(f'{model_name}')\n",
    "        plt.xlabel('Threshold')\n",
    "        plt.ylabel('Score')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Execução\n",
    "\n",
    "if __name__ == \"__main__\":     \n",
    "    \n",
    "    print(f\"\\n Para Executar:\")\n",
    "    print(f\"   results, table, best = optimize_all_models_thresholds()\")\n",
    "    \n",
    "\n",
    "# results, table, best_model = optimize_all_models_thresholds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-25T03:28:47.640592Z",
     "iopub.status.busy": "2025-06-25T03:28:47.640098Z",
     "iopub.status.idle": "2025-06-25T03:30:06.744282Z",
     "shell.execute_reply": "2025-06-25T03:30:06.743456Z",
     "shell.execute_reply.started": "2025-06-25T03:28:47.640572Z"
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "results, table, best_model = optimize_all_models_thresholds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-25T03:50:55.796072Z",
     "iopub.status.busy": "2025-06-25T03:50:55.795463Z",
     "iopub.status.idle": "2025-06-25T03:50:55.823126Z",
     "shell.execute_reply": "2025-06-25T03:50:55.822538Z",
     "shell.execute_reply.started": "2025-06-25T03:50:55.796049Z"
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Bloco 7: Consolidação Final dos Resultados - Apenas dados tabulares\n",
    "# Dados Finais dos Experimentos (atualizar com resultados)                       \n",
    "\n",
    "# Resultados das 5 estratégias (Validation mAP@0.5)\n",
    "STRATEGIES_RESULTS = {\n",
    "    'Baseline': {\n",
    "        'validation_map': 90.8,\n",
    "        'description': 'YOLOv8s configurações padrão'\n",
    "    },\n",
    "    'Fine-tuning': {\n",
    "        'validation_map': 90.2,\n",
    "        'description': 'Learning rate reduzido, regularização aumentada'\n",
    "    },\n",
    "    'High Class Weight': {\n",
    "        'validation_map': 90.6,\n",
    "        'description': 'Ênfase na loss de classificação'\n",
    "    },\n",
    "    'High Regularization': {\n",
    "        'validation_map': 90.7,\n",
    "        'description': 'Dropout e weight decay aumentados'\n",
    "    },\n",
    "    'Minimal Augmentation': {\n",
    "        'validation_map': 91.9,\n",
    "        'description': 'Data augmentation para microscopia'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Thresholds otimizados individuais (do Bloco 6)\n",
    "OPTIMIZED_THRESHOLDS = {\n",
    "    'Baseline': 0.50,\n",
    "    'Fine-tuning': 0.40,\n",
    "    'High Class Weight': 0.40,\n",
    "    'High Regularization': 0.55,\n",
    "    'Minimal Augmentation': 0.45\n",
    "}\n",
    "\n",
    "# Resultados com thresholds otimizados individuais \n",
    "THRESHOLD_OPTIMIZED_RESULTS = {\n",
    "    'Baseline': {\n",
    "        'test_f1': 0.850,\n",
    "        'test_precision': 0.803,\n",
    "        'test_recall': 0.902,\n",
    "        'optimal_threshold': 0.50\n",
    "    },\n",
    "    'Fine-tuning': {\n",
    "        'test_f1': 0.837,\n",
    "        'test_precision': 0.793,\n",
    "        'test_recall': 0.886,\n",
    "        'optimal_threshold': 0.40\n",
    "    },\n",
    "    'High Class Weight': {\n",
    "        'test_f1': 0.844,\n",
    "        'test_precision': 0.796,\n",
    "        'test_recall': 0.899,\n",
    "        'optimal_threshold': 0.40\n",
    "    },\n",
    "    'High Regularization': {\n",
    "        'test_f1': 0.844,\n",
    "        'test_precision': 0.803,\n",
    "        'test_recall': 0.889,\n",
    "        'optimal_threshold': 0.55\n",
    "    },\n",
    "    'Minimal Augmentation': {\n",
    "        'test_f1': 0.851,        \n",
    "        'test_precision': 0.805,\n",
    "        'test_recall': 0.902,\n",
    "        'optimal_threshold': 0.45\n",
    "    }\n",
    "}\n",
    "\n",
    "# Funções de Consolidação\n",
    "\n",
    "def generate_final_summary():\n",
    "    \n",
    "    print(\"\\n Resumo Final dos Experimentos\")    \n",
    "    \n",
    "    # Preparar dados para tabela\n",
    "    data = []\n",
    "    \n",
    "    for strategy in STRATEGIES_RESULTS.keys():\n",
    "        row = {\n",
    "            'Estratégia': strategy,\n",
    "            'Descrição': STRATEGIES_RESULTS[strategy]['description'],\n",
    "            'Validation mAP@0.5': f\"{STRATEGIES_RESULTS[strategy]['validation_map']:.1f}%\",\n",
    "            'Threshold Ótimo': f\"{THRESHOLD_OPTIMIZED_RESULTS[strategy]['optimal_threshold']:.2f}\",\n",
    "            'Test F1-Score': f\"{THRESHOLD_OPTIMIZED_RESULTS[strategy]['test_f1']:.3f}\",\n",
    "            'Test Precision': f\"{THRESHOLD_OPTIMIZED_RESULTS[strategy]['test_precision']:.3f}\",\n",
    "            'Test Recall': f\"{THRESHOLD_OPTIMIZED_RESULTS[strategy]['test_recall']:.3f}\"\n",
    "        }\n",
    "        data.append(row)\n",
    "    \n",
    "    # Criar DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Ordenar por F1 Test (melhor para pior)\n",
    "    df['F1_numeric'] = df['Test F1-Score'].str.replace('', '').astype(float)\n",
    "    df = df.sort_values('F1_numeric', ascending=False)\n",
    "    df = df.drop('F1_numeric', axis=1)\n",
    "    \n",
    "    # Exibir tabela\n",
    "    print(\"\\n Tabela Final dos Resultados (thresholds individuais otimizados):\")    \n",
    "    print(df.to_string(index=False))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def analyze_threshold_patterns():\n",
    "    \n",
    "    print(\"\\n Análise dos Thresholds Otimizados\")    \n",
    "    \n",
    "    thresholds = list(OPTIMIZED_THRESHOLDS.values())\n",
    "    strategies = list(OPTIMIZED_THRESHOLDS.keys())\n",
    "    \n",
    "    print(f\"\\n Distribuição dos Thresholds:\")\n",
    "    for strategy, threshold in OPTIMIZED_THRESHOLDS.items():\n",
    "        f1_score = THRESHOLD_OPTIMIZED_RESULTS[strategy]['test_f1']\n",
    "        print(f\"   • {strategy:20s}: {threshold:.2f} → F1: {f1_score:.3f}\")\n",
    "    \n",
    "    print(f\"\\n Estatísicas dos Thresholds:\")\n",
    "    print(f\"   • Threshold mais baixo: {min(thresholds):.2f}\")\n",
    "    print(f\"   • Threshold mais alto: {max(thresholds):.2f}\")\n",
    "    print(f\"   • Threshold médio: {np.mean(thresholds):.2f}\")\n",
    "    print(f\"   • Desvio padrão: {np.std(thresholds):.3f}\")\n",
    "    print(f\"   • Range: {max(thresholds) - min(thresholds):.2f}\")\n",
    "    \n",
    "    # Análise por agrupamento\n",
    "    threshold_groups = {}\n",
    "    for strategy, threshold in OPTIMIZED_THRESHOLDS.items():\n",
    "        if threshold not in threshold_groups:\n",
    "            threshold_groups[threshold] = []\n",
    "        threshold_groups[threshold].append(strategy)\n",
    "    \n",
    "    print(f\"\\n Agrupamento por Thresholds:\")\n",
    "    for threshold, group in sorted(threshold_groups.items()):\n",
    "        print(f\"   • {threshold:.2f}: {', '.join(group)}\")\n",
    "    \n",
    "    return {\n",
    "        'threshold_stats': {\n",
    "            'min': min(thresholds),\n",
    "            'max': max(thresholds),\n",
    "            'mean': np.mean(thresholds),\n",
    "            'std': np.std(thresholds)\n",
    "        },\n",
    "        'threshold_groups': threshold_groups\n",
    "    }\n",
    "\n",
    "def analyze_final_metrics():\n",
    "   \n",
    "    print(\"\\n Análise dos Resultados\")    \n",
    "    \n",
    "    # Extrair métricas\n",
    "    f1_scores = [THRESHOLD_OPTIMIZED_RESULTS[strategy]['test_f1'] for strategy in STRATEGIES_RESULTS.keys()]\n",
    "    precisions = [THRESHOLD_OPTIMIZED_RESULTS[strategy]['test_precision'] for strategy in STRATEGIES_RESULTS.keys()]\n",
    "    recalls = [THRESHOLD_OPTIMIZED_RESULTS[strategy]['test_recall'] for strategy in STRATEGIES_RESULTS.keys()]\n",
    "    validation_maps = [STRATEGIES_RESULTS[strategy]['validation_map'] for strategy in STRATEGIES_RESULTS.keys()]\n",
    "    \n",
    "    # Estatísticas descritivas\n",
    "    print(f\"\\n F1-SCORE (Test Set, thresholds individuais otimizados):\")\n",
    "    print(f\"   • Melhor: {max(f1_scores):.3f}\")\n",
    "    print(f\"   • Pior: {min(f1_scores):.3f}\")\n",
    "    print(f\"   • Média: {np.mean(f1_scores):.3f}\")\n",
    "    print(f\"   • Desvio padrão: {np.std(f1_scores):.3f}\")\n",
    "    print(f\"   • Range: {max(f1_scores) - min(f1_scores):.3f}\")\n",
    "    \n",
    "    print(f\"\\n PRECISION (Test Set):\")\n",
    "    print(f\"   • Melhor: {max(precisions):.3f}\")\n",
    "    print(f\"   • Pior: {min(precisions):.3f}\")\n",
    "    print(f\"   • Média: {np.mean(precisions):.3f}\")\n",
    "    print(f\"   • Desvio padrão: {np.std(precisions):.3f}\")\n",
    "    \n",
    "    print(f\"\\n RECALL (Test Set):\")\n",
    "    print(f\"   • Melhor: {max(recalls):.3f}\")\n",
    "    print(f\"   • Pior: {min(recalls):.3f}\")\n",
    "    print(f\"   • Média: {np.mean(recalls):.3f}\")\n",
    "    print(f\"   • Desvio padrão: {np.std(recalls):.3f}\")\n",
    "    \n",
    "    print(f\"\\n VALIDATION mAP@0.5:\")\n",
    "    print(f\"   • Melhor: {max(validation_maps):.1f}%\")\n",
    "    print(f\"   • Pior: {min(validation_maps):.1f}%\")\n",
    "    print(f\"   • Melhoria total: {max(validation_maps) - min(validation_maps):.1f} pontos percentuais\")\n",
    "    \n",
    "    return {\n",
    "        'f1_stats': {\n",
    "            'max': max(f1_scores),\n",
    "            'min': min(f1_scores),\n",
    "            'mean': np.mean(f1_scores),\n",
    "            'std': np.std(f1_scores)\n",
    "        },\n",
    "        'precision_stats': {\n",
    "            'max': max(precisions),\n",
    "            'min': min(precisions),\n",
    "            'mean': np.mean(precisions),\n",
    "            'std': np.std(precisions)\n",
    "        },\n",
    "        'recall_stats': {\n",
    "            'max': max(recalls),\n",
    "            'min': min(recalls),\n",
    "            'mean': np.mean(recalls),\n",
    "            'std': np.std(recalls)\n",
    "        },\n",
    "        'validation_improvement': max(validation_maps) - min(validation_maps)\n",
    "    }\n",
    "\n",
    "def identify_best_model():\n",
    "    \n",
    "    print(\"\\n Identificação do Melhor Modelo\")    \n",
    "    \n",
    "    # Encontrar melhor F1\n",
    "    best_f1 = 0\n",
    "    best_strategy = \"\"\n",
    "    \n",
    "    for strategy, results in THRESHOLD_OPTIMIZED_RESULTS.items():\n",
    "        if results['test_f1'] > best_f1:\n",
    "            best_f1 = results['test_f1']\n",
    "            best_strategy = strategy\n",
    "    \n",
    "    # Dados do melhor modelo\n",
    "    best_validation_map = STRATEGIES_RESULTS[best_strategy]['validation_map']\n",
    "    best_precision = THRESHOLD_OPTIMIZED_RESULTS[best_strategy]['test_precision']\n",
    "    best_recall = THRESHOLD_OPTIMIZED_RESULTS[best_strategy]['test_recall']\n",
    "    best_threshold = THRESHOLD_OPTIMIZED_RESULTS[best_strategy]['optimal_threshold']\n",
    "    \n",
    "    print(f\" Melhor Estratégia: {best_strategy}\")\n",
    "    print(f\"     Validation mAP@0.5: {best_validation_map:.1f}%\")\n",
    "    print(f\"     Test F1-Score: {best_f1:.3f}\")\n",
    "    print(f\"     Test Precision: {best_precision:.3f}\")\n",
    "    print(f\"     Test Recall: {best_recall:.3f}\")\n",
    "    print(f\"      Threshold otimizado: {best_threshold:.2f}\")\n",
    "    \n",
    "    # Melhoria vs baseline\n",
    "    baseline_f1 = THRESHOLD_OPTIMIZED_RESULTS['Baseline']['test_f1']\n",
    "    baseline_map = STRATEGIES_RESULTS['Baseline']['validation_map']\n",
    "    baseline_threshold = THRESHOLD_OPTIMIZED_RESULTS['Baseline']['optimal_threshold']\n",
    "    \n",
    "    improvement_f1 = ((best_f1 - baseline_f1) / baseline_f1) * 100\n",
    "    improvement_map = best_validation_map - baseline_map\n",
    "    \n",
    "    print(f\"\\n Melhoria vs Baseline:\")\n",
    "    print(f\"   • F1-Score: +{improvement_f1:.1f}% ({baseline_f1:.3f} → {best_f1:.3f})\")\n",
    "    print(f\"   • mAP@0.5: +{improvement_map:.1f} p.p. ({baseline_map:.1f}% → {best_validation_map:.1f}%)\")\n",
    "    print(f\"   • Threshold: {baseline_threshold:.2f} → {best_threshold:.2f}\")\n",
    "    \n",
    "    # Análise da diferença marginal\n",
    "    f1_diff = best_f1 - baseline_f1\n",
    "    print(f\"\\n Análise da Performance:\")\n",
    "    if f1_diff < 0.005:\n",
    "        print(f\"    Diferença marginal: {f1_diff:.3f}\")\n",
    "        print(f\"    Ambos os modelos têm performance muito similar\")        \n",
    "    else:\n",
    "        print(f\"    Melhoria significativa: {f1_diff:.3f}\")\n",
    "        print(f\"    {best_strategy} claramente superior\")\n",
    "    \n",
    "    return {\n",
    "        'best_strategy': best_strategy,\n",
    "        'best_f1': best_f1,\n",
    "        'best_precision': best_precision,\n",
    "        'best_recall': best_recall,\n",
    "        'best_threshold': best_threshold,\n",
    "        'improvement_f1_percent': improvement_f1,\n",
    "        'improvement_map_points': improvement_map,\n",
    "        'f1_difference': f1_diff\n",
    "    }\n",
    "\n",
    "def validate_methodology():\n",
    "    \n",
    "    print(\"\\n Validação\")\n",
    "        \n",
    "    # Verificar se threshold optimization funcionou\n",
    "    baseline_f1 = THRESHOLD_OPTIMIZED_RESULTS['Baseline']['test_f1']\n",
    "    \n",
    "    print(f\" Comparação com Baseline (threshold otimizado):\")\n",
    "    improvements = []\n",
    "    for strategy, results in THRESHOLD_OPTIMIZED_RESULTS.items():\n",
    "        if strategy != 'Baseline':\n",
    "            improvement = results['test_f1'] - baseline_f1\n",
    "            improvements.append(improvement)\n",
    "            status = \"\" if improvement > 0 else \"\"\n",
    "            threshold = results['optimal_threshold']\n",
    "            print(f\"   {status} {strategy:20s}: {improvement:+.3f} (t={threshold:.2f})\")\n",
    "    \n",
    "    # Estatísticas gerais\n",
    "    all_improved = all(imp > 0 for imp in improvements)\n",
    "    avg_improvement = np.mean(improvements)\n",
    "    \n",
    "    print(f\"\\n Resumo da Validação:\")    \n",
    "    print(f\"   • Estratégias que melhoraram baseline: {sum(1 for i in improvements if i > 0)}/4\")\n",
    "    print(f\"   • Melhoria média vs baseline: {avg_improvement:+.3f}\")\n",
    "    print(f\"   • Range de thresholds: {min(OPTIMIZED_THRESHOLDS.values()):.2f} - {max(OPTIMIZED_THRESHOLDS.values()):.2f}\")  \n",
    "        \n",
    "    return {\n",
    "        'all_improved': all_improved,\n",
    "        'average_improvement': avg_improvement,\n",
    "        'individual_improvements': improvements,\n",
    "        'threshold_range': max(OPTIMIZED_THRESHOLDS.values()) - min(OPTIMIZED_THRESHOLDS.values())\n",
    "    }\n",
    "\n",
    "def export_final_results():\n",
    "    \n",
    "    print(\"\\n Exportando Resultados Finais\")\n",
    "   \n",
    "    # Gerar DataFrame completo\n",
    "    df = generate_final_summary()\n",
    "    \n",
    "    # Salvar CSV\n",
    "    output_file = \"resultados_finais_tcc_thresholds_otimizados.csv\"\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\" Arquivo salvo: {output_file}\")\n",
    "    \n",
    "    # Salvar resumo \n",
    "    best_model = identify_best_model()\n",
    "    \n",
    "    summary_text = f\"\"\"Resumo - Classificação de Células\n",
    "\n",
    " Melhor Modelo: {best_model['best_strategy']}\n",
    " F1-Score Final: {best_model['best_f1']:.3f}\n",
    " Precision: {best_model['best_precision']:.3f}\n",
    " Recall: {best_model['best_recall']:.3f}\n",
    "  Threshold Otimizado: {best_model['best_threshold']:.2f}\n",
    "\n",
    " Melhoria vs Baseline:\n",
    "F1-Score: +{best_model['improvement_f1_percent']:.1f}%\n",
    "mAP@0.5: +{best_model['improvement_map_points']:.1f} pontos percentuais\n",
    "\n",
    " Metodologia:\n",
    " 5 estratégias de otimização testadas\n",
    " Threshold optimization individual para cada modelo\n",
    " Validação em test set independente\n",
    " Seeds fixos para reprodutibilidade\n",
    " Range de thresholds: {min(OPTIMIZED_THRESHOLDS.values()):.2f} - {max(OPTIMIZED_THRESHOLDS.values()):.2f}\n",
    "\n",
    " THRESHOLDS OTIMIZADOS:\n",
    "{chr(10).join([f\"   • {strategy}: {threshold:.2f}\" for strategy, threshold in OPTIMIZED_THRESHOLDS.items()])}\n",
    "\"\"\"\n",
    "    \n",
    "    summary_file = \"resumo_tcc_thresholds.txt\"\n",
    "    with open(summary_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(summary_text)\n",
    "    print(f\" Resumo salvo: {summary_file}\")\n",
    "    \n",
    "    return df, summary_text\n",
    "\n",
    "# Função Principal\n",
    "\n",
    "def run_final_consolidation():    \n",
    "    \n",
    "    # Executar todas as análises\n",
    "    df_results = generate_final_summary()\n",
    "    threshold_analysis = analyze_threshold_patterns()\n",
    "    stats = analyze_final_metrics()\n",
    "    best_model = identify_best_model()\n",
    "    validation = validate_methodology()\n",
    "    \n",
    "    print(f\"\\n Conclusão:\")    \n",
    "    print(f\" Melhor modelo identificado: {best_model['best_strategy']}\")\n",
    "    print(f\" Performance final: {best_model['best_f1']:.3f} F1-Score\")\n",
    "    print(f\"  Threshold ótimo: {best_model['best_threshold']:.2f}\")   \n",
    "    \n",
    "    return {\n",
    "        'summary_table': df_results,\n",
    "        'threshold_analysis': threshold_analysis,\n",
    "        'statistics': stats,\n",
    "        'best_model': best_model,\n",
    "        'methodology_validation': validation\n",
    "    }\n",
    "\n",
    "# Executar Consolidação\n",
    "\n",
    "if __name__ == \"__main__\":    \n",
    "    print(\"  Para executar:\")\n",
    "    print(\"  results = run_final_consolidation()  # Análise completa\")\n",
    "    print(\"  df = generate_final_summary()        # Apenas tabela\")\n",
    "    print(\"  best = identify_best_model()         # Apenas melhor modelo\")\n",
    "    print(\"  export_final_results()               # Salvar arquivos\")   \n",
    "    \n",
    "\n",
    "# results = run_final_consolidation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-25T03:51:24.918799Z",
     "iopub.status.busy": "2025-06-25T03:51:24.918517Z",
     "iopub.status.idle": "2025-06-25T03:51:24.927969Z",
     "shell.execute_reply": "2025-06-25T03:51:24.927146Z",
     "shell.execute_reply.started": "2025-06-25T03:51:24.918758Z"
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "results = run_final_consolidation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-25T04:18:15.774602Z",
     "iopub.status.busy": "2025-06-25T04:18:15.774050Z",
     "iopub.status.idle": "2025-06-25T04:18:15.836432Z",
     "shell.execute_reply": "2025-06-25T04:18:15.835812Z",
     "shell.execute_reply.started": "2025-06-25T04:18:15.774577Z"
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Bloco 8: Análise de métricas para detecção de células microscópicas\n",
    "# Thresholds individuais otimizados\n",
    "\n",
    "# 1. Configuração dos Dados\n",
    "\n",
    "# Resultados com thresholds individuais otimizados\n",
    "STRATEGIES_RESULTS = {\n",
    "    'Baseline': {\n",
    "        'validation_map': 90.8,\n",
    "        'test_f1': 0.850,\n",
    "        'test_precision': 0.803,\n",
    "        'test_recall': 0.902,\n",
    "        'optimal_threshold': 0.50,\n",
    "        'description': 'YOLOv8s configurações padrão'\n",
    "    },\n",
    "    'Fine-tuning': {\n",
    "        'validation_map': 90.2,\n",
    "        'test_f1': 0.837,\n",
    "        'test_precision': 0.793,\n",
    "        'test_recall': 0.886,\n",
    "        'optimal_threshold': 0.40,\n",
    "        'description': 'Learning rate reduzido'\n",
    "    },\n",
    "    'High Class Weight': {\n",
    "        'validation_map': 90.6,\n",
    "        'test_f1': 0.844,\n",
    "        'test_precision': 0.796,\n",
    "        'test_recall': 0.899,\n",
    "        'optimal_threshold': 0.40,\n",
    "        'description': 'Ênfase na loss de classificação'\n",
    "    },\n",
    "    'High Regularization': {\n",
    "        'validation_map': 90.7,\n",
    "        'test_f1': 0.844,\n",
    "        'test_precision': 0.803,\n",
    "        'test_recall': 0.889,\n",
    "        'optimal_threshold': 0.55,\n",
    "        'description': 'Dropout e weight decay aumentados'\n",
    "    },\n",
    "    'Minimal Augmentation': {\n",
    "        'validation_map': 91.9,\n",
    "        'test_f1': 0.851,        \n",
    "        'test_precision': 0.805,\n",
    "        'test_recall': 0.902,\n",
    "        'optimal_threshold': 0.45,\n",
    "        'description': 'Data augmentation para microscopia'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Thresholds otimizados individuais\n",
    "OPTIMIZED_THRESHOLDS = {\n",
    "    'Baseline': 0.50,\n",
    "    'Fine-tuning': 0.40,\n",
    "    'High Class Weight': 0.40,\n",
    "    'High Regularization': 0.55,\n",
    "    'Minimal Augmentation': 0.45\n",
    "}\n",
    "\n",
    "# Métricas detalhadas do melhor modelo (Minimal Augmentation)\n",
    "BEST_MODEL_METRICS = {\n",
    "    'COM_corante': {\n",
    "        'precision': 0.812,  # Estimado baseado no padrão\n",
    "        'recall': 0.895,\n",
    "        'f1': 0.852,\n",
    "        'support': 262\n",
    "    },\n",
    "    'SEM_corante': {\n",
    "        'precision': 0.798,\n",
    "        'recall': 0.909,\n",
    "        'f1': 0.850,\n",
    "        'support': 192\n",
    "    }\n",
    "}\n",
    "\n",
    "# Dados da curva de threshold do Minimal Augmentation\n",
    "THRESHOLD_CURVE_DATA = {\n",
    "    'thresholds': [0.30, 0.35, 0.40, 0.45, 0.50, 0.55, 0.60, 0.65, 0.70],\n",
    "    'precision': [0.742, 0.767, 0.789, 0.805, 0.821, 0.838, 0.856, 0.875, 0.894],\n",
    "    'recall': [0.934, 0.923, 0.915, 0.902, 0.888, 0.871, 0.852, 0.829, 0.803],\n",
    "    'f1': [0.826, 0.836, 0.846, 0.851, 0.853, 0.854, 0.854, 0.852, 0.846]\n",
    "}\n",
    "\n",
    "# 2. DASHBOARD PRINCIPAL\n",
    "\n",
    "def create_dashboard():\n",
    "    \n",
    "    print(\"\\n Gerando dashboard com thresholds individuais otimizados...\")\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))    \n",
    "    \n",
    "    # 1. Ranking por F1-SCORE (TEST SET)\n",
    "        \n",
    "    # Ordenar estratégias por F1-Score\n",
    "    sorted_strategies = sorted(STRATEGIES_RESULTS.items(), \n",
    "                              key=lambda x: x[1]['test_f1'], reverse=True)\n",
    "    \n",
    "    models = [s[0] for s in sorted_strategies]\n",
    "    f1_scores = [s[1]['test_f1'] for s in sorted_strategies]\n",
    "    thresholds = [s[1]['optimal_threshold'] for s in sorted_strategies]\n",
    "    colors = ['#FECA57', '#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4']\n",
    "    \n",
    "    bars = axes[0,0].bar(models, f1_scores, color=colors, alpha=0.8, \n",
    "                        edgecolor='black', linewidth=1.5)\n",
    "    \n",
    "    # Adicionar valores e thresholds\n",
    "    for i, (bar, f1, threshold) in enumerate(zip(bars, f1_scores, thresholds)):\n",
    "        height = bar.get_height()\n",
    "        # F1-Score no topo\n",
    "        axes[0,0].text(bar.get_x() + bar.get_width()/2., height + 0.005,\n",
    "                f'{f1:.3f}', ha='center', va='bottom', fontweight='bold', fontsize=10)\n",
    "        # Threshold embaixo\n",
    "        axes[0,0].text(bar.get_x() + bar.get_width()/2., height - 0.015,\n",
    "                f't={threshold:.2f}', ha='center', va='top', \n",
    "                fontweight='bold', color='white', fontsize=9)\n",
    "        # Posição no ranking\n",
    "        axes[0,0].text(bar.get_x() + bar.get_width()/2., height - 0.035,\n",
    "                f'{i+1}º', ha='center', va='top', \n",
    "                fontweight='bold', color='yellow', fontsize=11)\n",
    "    \n",
    "    # Destacar o vencedor\n",
    "    bars[0].set_edgecolor('gold')\n",
    "    bars[0].set_linewidth(3)\n",
    "    \n",
    "    axes[0,0].set_title('Ranking Final: F1-Score com Thresholds Otimizados\\n(Test Set)', \n",
    "                       fontsize=12, fontweight='bold')\n",
    "    axes[0,0].set_ylabel('F1-Score', fontsize=10)\n",
    "    axes[0,0].set_ylim(0.82, 0.86)\n",
    "    axes[0,0].grid(True, alpha=0.3)\n",
    "    axes[0,0].tick_params(axis='x', rotation=15, labelsize=9)\n",
    "    \n",
    "    # 2. Distribuição dos Thresholds   \n",
    "    \n",
    "    threshold_values = list(OPTIMIZED_THRESHOLDS.values())\n",
    "    threshold_counts = {}\n",
    "    for t in threshold_values:\n",
    "        threshold_counts[t] = threshold_counts.get(t, 0) + 1\n",
    "    \n",
    "    thresholds_unique = list(threshold_counts.keys())\n",
    "    counts = list(threshold_counts.values())\n",
    "    \n",
    "    bars = axes[0,1].bar(thresholds_unique, counts, color='lightcoral', \n",
    "                        alpha=0.8, edgecolor='black', linewidth=1.5)\n",
    "    \n",
    "    for bar, count in zip(bars, counts):\n",
    "        height = bar.get_height()\n",
    "        axes[0,1].text(bar.get_x() + bar.get_width()/2., height + 0.05,\n",
    "                f'{int(count)}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # Adicionar labels dos modelos\n",
    "    for threshold, models_list in threshold_counts.items():\n",
    "        models_with_threshold = [k for k, v in OPTIMIZED_THRESHOLDS.items() if v == threshold]\n",
    "        y_pos = threshold_counts[threshold] - 0.3\n",
    "        axes[0,1].text(threshold, y_pos, '\\n'.join(models_with_threshold), \n",
    "                      ha='center', va='center', fontsize=8, \n",
    "                      bbox=dict(boxstyle=\"round,pad=0.2\", facecolor='white', alpha=0.7))\n",
    "    \n",
    "    axes[0,1].set_title('Distribuição dos Thresholds Otimizados\\n(Frequência por Threshold)', \n",
    "                       fontsize=12, fontweight='bold')\n",
    "    axes[0,1].set_xlabel('Threshold', fontsize=10)\n",
    "    axes[0,1].set_ylabel('Número de Modelos', fontsize=10)\n",
    "    axes[0,1].grid(True, alpha=0.3)\n",
    "    axes[0,1].set_ylim(0, max(counts) + 1)\n",
    "    \n",
    "    # 3. Métricas do Melhor Modelo    \n",
    "    \n",
    "    classes = list(BEST_MODEL_METRICS.keys())\n",
    "    metrics = ['precision', 'recall', 'f1']\n",
    "    \n",
    "    x = np.arange(len(classes))\n",
    "    width = 0.25\n",
    "    \n",
    "    for i, metric in enumerate(metrics):\n",
    "        values = [BEST_MODEL_METRICS[cls][metric] for cls in classes]\n",
    "        bars = axes[0,2].bar(x + i*width, values, width, label=metric.title(), \n",
    "                      alpha=0.8, edgecolor='black', linewidth=1)\n",
    "        \n",
    "        for bar, value in zip(bars, values):\n",
    "            height = bar.get_height()\n",
    "            axes[0,2].text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                    f'{value:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    axes[0,2].set_title('Minimal Augmentation: Métricas por Classe\\n(Melhor Modelo, threshold=0.45)', \n",
    "                       fontsize=12, fontweight='bold')\n",
    "    axes[0,2].set_ylabel('Score', fontsize=10)\n",
    "    axes[0,2].set_xticks(x + width)\n",
    "    axes[0,2].set_xticklabels([cls.replace('_', '\\n') for cls in classes], fontsize=9)\n",
    "    axes[0,2].legend(fontsize=9)\n",
    "    axes[0,2].grid(True, alpha=0.3)\n",
    "    axes[0,2].set_ylim(0.75, 0.95)    \n",
    "    \n",
    "    # 4. Curva de Threshold do Melhor Modelo    \n",
    "    \n",
    "    thresholds = THRESHOLD_CURVE_DATA['thresholds']\n",
    "    \n",
    "    axes[1,0].plot(thresholds, THRESHOLD_CURVE_DATA['precision'], 'b-', linewidth=2, \n",
    "                   label='Precision', marker='o', markersize=4)\n",
    "    axes[1,0].plot(thresholds, THRESHOLD_CURVE_DATA['recall'], 'r-', linewidth=2, \n",
    "                   label='Recall', marker='s', markersize=4)\n",
    "    axes[1,0].plot(thresholds, THRESHOLD_CURVE_DATA['f1'], 'g-', linewidth=2, \n",
    "                   label='F1-Score', marker='^', markersize=4)\n",
    "    \n",
    "    # Marcar threshold ótimo\n",
    "    optimal_threshold = STRATEGIES_RESULTS['Minimal Augmentation']['optimal_threshold']\n",
    "    optimal_f1 = STRATEGIES_RESULTS['Minimal Augmentation']['test_f1']\n",
    "    \n",
    "    axes[1,0].axvline(x=optimal_threshold, color='orange', linestyle='--', linewidth=2, \n",
    "               label=f'Ótimo: {optimal_threshold:.2f}')\n",
    "    axes[1,0].scatter(optimal_threshold, optimal_f1, color='orange', s=100, zorder=5)\n",
    "    \n",
    "    axes[1,0].set_title('Threshold Optimization: Minimal Augmentation\\n(Validation Set)', \n",
    "                       fontsize=12, fontweight='bold')\n",
    "    axes[1,0].set_xlabel('Threshold', fontsize=10)\n",
    "    axes[1,0].set_ylabel('Score', fontsize=10)\n",
    "    axes[1,0].legend(fontsize=9)\n",
    "    axes[1,0].grid(True, alpha=0.3)\n",
    "    axes[1,0].set_ylim(0.75, 0.95)\n",
    "    \n",
    "    # 5. Comparação Validation vs Test\n",
    "    \n",
    "    strategies = list(STRATEGIES_RESULTS.keys())\n",
    "    val_maps = [STRATEGIES_RESULTS[s]['validation_map'] for s in strategies]\n",
    "    test_f1s = [STRATEGIES_RESULTS[s]['test_f1'] for s in strategies]\n",
    "    \n",
    "    # Normalizar para comparar (mAP para %)\n",
    "    val_maps_norm = [v/100 for v in val_maps]  # Converter % para decimal\n",
    "    \n",
    "    x = np.arange(len(strategies))\n",
    "    width = 0.35\n",
    "    \n",
    "    bars1 = axes[1,1].bar(x - width/2, val_maps_norm, width, label='Validation mAP@0.5', \n",
    "                         alpha=0.8, color='skyblue', edgecolor='black')\n",
    "    bars2 = axes[1,1].bar(x + width/2, test_f1s, width, label='Test F1-Score', \n",
    "                         alpha=0.8, color='lightcoral', edgecolor='black')\n",
    "    \n",
    "    # Adicionar valores\n",
    "    for bar, val in zip(bars1, val_maps):\n",
    "        height = bar.get_height()\n",
    "        axes[1,1].text(bar.get_x() + bar.get_width()/2., height + 0.005,\n",
    "                f'{val:.1f}%', ha='center', va='bottom', fontsize=8)\n",
    "    \n",
    "    for bar, val in zip(bars2, test_f1s):\n",
    "        height = bar.get_height()\n",
    "        axes[1,1].text(bar.get_x() + bar.get_width()/2., height + 0.005,\n",
    "                f'{val:.3f}', ha='center', va='bottom', fontsize=8)\n",
    "    \n",
    "    axes[1,1].set_title('Consistência: Validation vs Test\\n(com thresholds otimizados)', \n",
    "                       fontsize=12, fontweight='bold')\n",
    "    axes[1,1].set_ylabel('Score', fontsize=10)\n",
    "    axes[1,1].set_xticks(x)\n",
    "    axes[1,1].set_xticklabels([s.replace(' ', '\\n') for s in strategies], fontsize=8)\n",
    "    axes[1,1].legend(fontsize=9)\n",
    "    axes[1,1].grid(True, alpha=0.3)\n",
    "    axes[1,1].set_ylim(0.80, 0.95)\n",
    "    \n",
    "    # 6. Summary Box\n",
    "        \n",
    "    axes[1,2].axis('off')\n",
    "    \n",
    "    # Encontrar melhor modelo\n",
    "    best_strategy = max(STRATEGIES_RESULTS.items(), key=lambda x: x[1]['test_f1'])\n",
    "    best_name = best_strategy[0]\n",
    "    best_data = best_strategy[1]\n",
    "    \n",
    "    # Calcular melhoria vs baseline\n",
    "    baseline_f1 = STRATEGIES_RESULTS['Baseline']['test_f1']\n",
    "    improvement = ((best_data['test_f1'] - baseline_f1) / baseline_f1) * 100\n",
    "    \n",
    "    # Análise de thresholds\n",
    "    threshold_range = max(OPTIMIZED_THRESHOLDS.values()) - min(OPTIMIZED_THRESHOLDS.values())\n",
    "    \n",
    "    summary_text = f\"\"\" Resultados Finais\n",
    "\n",
    " Melhor Modelo: {best_name}\n",
    "• Test F1-Score: {best_data['test_f1']:.3f}\n",
    "• Test Precision: {best_data['test_precision']:.3f}  \n",
    "• Test Recall: {best_data['test_recall']:.3f}\n",
    "• Threshold ótimo: {best_data['optimal_threshold']:.2f}\n",
    "• Validation mAP: {best_data['validation_map']:.1f}%\n",
    "\n",
    " Melhoria vs Baseline:\n",
    "• F1-Score: +{improvement:.1f}%\n",
    "• mAP: +{best_data['validation_map'] - STRATEGIES_RESULTS['Baseline']['validation_map']:.1f} p.p.\n",
    "\n",
    " Thresholds Otimizados:\n",
    "• Range: {min(OPTIMIZED_THRESHOLDS.values()):.2f} - {max(OPTIMIZED_THRESHOLDS.values()):.2f}\n",
    "• Variação: {threshold_range:.2f}\n",
    "• Necessidade de otimização individual\n",
    "\"\"\"\n",
    "    \n",
    "    axes[1,2].text(0.05, 0.95, summary_text, transform=axes[1,2].transAxes, fontsize=9,\n",
    "              verticalalignment='top', bbox=dict(boxstyle=\"round,pad=0.4\", \n",
    "              facecolor='lightgreen', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()    \n",
    "\n",
    "# 3. Gráficos Individuais\n",
    "\n",
    "def plot_ranking_final():\n",
    "    \n",
    "    print(\" Gerando: Ranking Final com Thresholds Individuais...\")\n",
    "    \n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    # Ordenar por F1-Score\n",
    "    sorted_strategies = sorted(STRATEGIES_RESULTS.items(), \n",
    "                              key=lambda x: x[1]['test_f1'], reverse=True)\n",
    "    \n",
    "    models = [s[0] for s in sorted_strategies]\n",
    "    f1_scores = [s[1]['test_f1'] for s in sorted_strategies]\n",
    "    thresholds = [s[1]['optimal_threshold'] for s in sorted_strategies]\n",
    "    colors = ['#FECA57', '#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4']\n",
    "    \n",
    "    bars = plt.bar(models, f1_scores, color=colors, alpha=0.9, \n",
    "                  edgecolor='black', linewidth=2)\n",
    "    \n",
    "    # Adicionar informações detalhadas\n",
    "    for i, (bar, f1, threshold, model) in enumerate(zip(bars, f1_scores, thresholds, models)):\n",
    "        height = bar.get_height()\n",
    "        \n",
    "        # F1-Score\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 0.003,\n",
    "                f'{f1:.3f}', ha='center', va='bottom', fontweight='bold', fontsize=12)\n",
    "        \n",
    "        # Threshold\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height - 0.008,\n",
    "                f'threshold: {threshold:.2f}', ha='center', va='top', \n",
    "                fontweight='bold', color='white', fontsize=10)\n",
    "        \n",
    "        # Posição\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height - 0.02,\n",
    "                f'{i+1}º lugar', ha='center', va='top', \n",
    "                fontweight='bold', color='yellow', fontsize=11)\n",
    "        \n",
    "        # Destacar vencedor\n",
    "        if i == 0:\n",
    "            bar.set_edgecolor('gold')\n",
    "            bar.set_linewidth(4)\n",
    "            # Adicionar coroa\n",
    "            plt.text(bar.get_x() + bar.get_width()/2., height + 0.015,\n",
    "                    '👑', ha='center', va='bottom', fontsize=16)\n",
    "    \n",
    "    plt.title(' Ranking Final: F1-Score com Thresholds Individuais Otimizados\\n(Test Set)', \n",
    "              fontsize=16, fontweight='bold', pad=20)\n",
    "    plt.ylabel('F1-Score', fontsize=14)\n",
    "    plt.xlabel('Estratégias de Otimização', fontsize=14)\n",
    "    \n",
    "    # Linha de baseline\n",
    "    baseline_f1 = STRATEGIES_RESULTS['Baseline']['test_f1']\n",
    "    plt.axhline(y=baseline_f1, color='red', linestyle='--', alpha=0.7, \n",
    "                label=f'Baseline: {baseline_f1:.3f}')\n",
    "    \n",
    "    plt.legend(fontsize=12)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.ylim(0.82, 0.86)\n",
    "    plt.xticks(rotation=15, fontsize=11)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_threshold_distribution():\n",
    "    \n",
    "    print(\" Gerando: Análise da Distribuição de Thresholds...\")\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Subplot 1: Histograma dos thresholds\n",
    "    threshold_values = list(OPTIMIZED_THRESHOLDS.values())\n",
    "    ax1.hist(threshold_values, bins=np.arange(0.35, 0.65, 0.05), \n",
    "            alpha=0.7, color='skyblue', edgecolor='black', linewidth=2)\n",
    "    \n",
    "    ax1.set_title('Distribuição dos Thresholds Otimizados', fontsize=14, fontweight='bold')\n",
    "    ax1.set_xlabel('Threshold', fontsize=12)\n",
    "    ax1.set_ylabel('Frequência', fontsize=12)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Adicionar estatísticas\n",
    "    mean_threshold = np.mean(threshold_values)\n",
    "    std_threshold = np.std(threshold_values)\n",
    "    ax1.axvline(mean_threshold, color='red', linestyle='--', linewidth=2,\n",
    "                label=f'Média: {mean_threshold:.2f}')\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Subplot 2: Threshold vs Performance\n",
    "    strategies = list(STRATEGIES_RESULTS.keys())\n",
    "    thresholds = [STRATEGIES_RESULTS[s]['optimal_threshold'] for s in strategies]\n",
    "    f1_scores = [STRATEGIES_RESULTS[s]['test_f1'] for s in strategies]\n",
    "    colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FECA57']\n",
    "    \n",
    "    scatter = ax2.scatter(thresholds, f1_scores, c=colors, s=150, \n",
    "                         alpha=0.8, edgecolors='black', linewidth=2)\n",
    "    \n",
    "    # Adicionar labels\n",
    "    for i, (threshold, f1, strategy) in enumerate(zip(thresholds, f1_scores, strategies)):\n",
    "        ax2.annotate(strategy, (threshold, f1), xytext=(5, 5), \n",
    "                    textcoords='offset points', fontsize=9, fontweight='bold')\n",
    "    \n",
    "    ax2.set_title('Threshold vs Performance', fontsize=14, fontweight='bold')\n",
    "    ax2.set_xlabel('Threshold Otimizado', fontsize=12)\n",
    "    ax2.set_ylabel('F1-Score (Test Set)', fontsize=12)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_threshold_curves():\n",
    "    \n",
    "    print(\" Gerando: Curvas de Threshold Optimization...\")\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    thresholds = THRESHOLD_CURVE_DATA['thresholds']\n",
    "    \n",
    "    plt.plot(thresholds, THRESHOLD_CURVE_DATA['precision'], 'b-', linewidth=3, \n",
    "             label='Precision', marker='o', markersize=8)\n",
    "    plt.plot(thresholds, THRESHOLD_CURVE_DATA['recall'], 'r-', linewidth=3, \n",
    "             label='Recall', marker='s', markersize=8)\n",
    "    plt.plot(thresholds, THRESHOLD_CURVE_DATA['f1'], 'g-', linewidth=3, \n",
    "             label='F1-Score', marker='^', markersize=8)\n",
    "    \n",
    "    # Marcar threshold ótimo\n",
    "    optimal_threshold = STRATEGIES_RESULTS['Minimal Augmentation']['optimal_threshold']\n",
    "    optimal_f1 = STRATEGIES_RESULTS['Minimal Augmentation']['test_f1']\n",
    "    \n",
    "    plt.axvline(x=optimal_threshold, color='orange', linestyle='--', linewidth=3, \n",
    "                label=f'Threshold Ótimo: {optimal_threshold:.2f}')\n",
    "    plt.scatter(optimal_threshold, optimal_f1, color='orange', s=200, zorder=5,\n",
    "                edgecolor='black', linewidth=2)\n",
    "    \n",
    "    # Zona estável\n",
    "    stable_zone = [0.40, 0.50]\n",
    "    plt.axvspan(stable_zone[0], stable_zone[1], alpha=0.2, color='green', \n",
    "                label='Zona Estável (F1 > 0.85)')\n",
    "    \n",
    "    plt.title(f'Threshold Optimization: Minimal Augmentation\\nF1-Score Máximo: {optimal_f1:.3f} em threshold={optimal_threshold:.2f}', \n",
    "              fontsize=16, fontweight='bold', pad=20)\n",
    "    plt.xlabel('Threshold de Confiança', fontsize=14)\n",
    "    plt.ylabel('Score', fontsize=14)\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.ylim(0.75, 0.95)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_consistency_analysis():\n",
    "    \n",
    "    print(\"🔍 Gerando: Análise de Consistência...\")\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    strategies = list(STRATEGIES_RESULTS.keys())\n",
    "    val_maps = [STRATEGIES_RESULTS[s]['validation_map'] for s in strategies]\n",
    "    test_f1s = [STRATEGIES_RESULTS[s]['test_f1'] for s in strategies]\n",
    "    thresholds = [STRATEGIES_RESULTS[s]['optimal_threshold'] for s in strategies]\n",
    "    \n",
    "    # Normalizar validation mAP para comparar com F1\n",
    "    val_maps_norm = [v/100 for v in val_maps]\n",
    "    \n",
    "    x = np.arange(len(strategies))\n",
    "    width = 0.35\n",
    "    \n",
    "    bars1 = plt.bar(x - width/2, val_maps_norm, width, label='Validation mAP@0.5 (norm)', \n",
    "                   alpha=0.8, color='skyblue', edgecolor='black')\n",
    "    bars2 = plt.bar(x + width/2, test_f1s, width, label='Test F1-Score', \n",
    "                   alpha=0.8, color='lightcoral', edgecolor='black')\n",
    "    \n",
    "    # Adicionar valores e thresholds\n",
    "    for bar, val, threshold in zip(bars1, val_maps, thresholds):\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                f'{val:.1f}%\\nt={threshold:.2f}', ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    for bar, val in zip(bars2, test_f1s):\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                f'{val:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    plt.title('Consistência: Validation vs Test\\n(com Thresholds Individuais Otimizados)', \n",
    "              fontsize=16, fontweight='bold', pad=20)\n",
    "    plt.ylabel('Score', fontsize=14)\n",
    "    plt.xlabel('Estratégias', fontsize=14)\n",
    "    plt.xticks(x, [s.replace(' ', '\\n') for s in strategies], fontsize=10)\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.ylim(0.80, 0.95)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 4. Funções de Controle\n",
    "\n",
    "def generate_all_plots():\n",
    "    \n",
    "    print(\" Gerando TODOS os gráficos individuais...\")\n",
    "    \n",
    "    plot_ranking_final()\n",
    "    plot_threshold_distribution()\n",
    "    plot_threshold_curves()\n",
    "    plot_consistency_analysis()\n",
    "    \n",
    "    print(\"\\n Todos os gráficos individuais foram gerados!\")\n",
    "\n",
    "def generate_dashboard():    \n",
    "    print(\" Gerando dashboard completo...\")\n",
    "    create_dashboard()\n",
    "\n",
    "def analyze_results():      \n",
    "    \n",
    "    # Análise dos F1-Scores\n",
    "    f1_scores = [STRATEGIES_RESULTS[s]['test_f1'] for s in STRATEGIES_RESULTS.keys()]\n",
    "    thresholds = [STRATEGIES_RESULTS[s]['optimal_threshold'] for s in STRATEGIES_RESULTS.keys()]\n",
    "    \n",
    "    print(f\" F1-SCORES (Test Set):\")\n",
    "    print(f\"   • Melhor: {max(f1_scores):.3f}\")\n",
    "    print(f\"   • Pior: {min(f1_scores):.3f}\")\n",
    "    print(f\"   • Média: {np.mean(f1_scores):.3f}\")\n",
    "    print(f\"   • Desvio padrão: {np.std(f1_scores):.3f}\")\n",
    "    print(f\"   • Range: {max(f1_scores) - min(f1_scores):.3f}\")\n",
    "    \n",
    "    print(f\"\\n Threshold Otimizados:\")\n",
    "    print(f\"   • Threshold mais baixo: {min(thresholds):.2f}\")\n",
    "    print(f\"   • Threshold mais alto: {max(thresholds):.2f}\")\n",
    "    print(f\"   • Threshold médio: {np.mean(thresholds):.2f}\")\n",
    "    print(f\"   • Desvio padrão: {np.std(thresholds):.3f}\")\n",
    "    print(f\"   • Range: {max(thresholds) - min(thresholds):.2f}\")\n",
    "    \n",
    "    # Análise por estratégia\n",
    "    best_strategy = max(STRATEGIES_RESULTS.items(), key=lambda x: x[1]['test_f1'])\n",
    "    baseline = STRATEGIES_RESULTS['Baseline']\n",
    "    \n",
    "    print(f\"\\n Melhor Modelo:\")\n",
    "    print(f\"   • Estratégia: {best_strategy[0]}\")\n",
    "    print(f\"   • F1-Score: {best_strategy[1]['test_f1']:.3f}\")\n",
    "    print(f\"   • Threshold: {best_strategy[1]['optimal_threshold']:.2f}\")\n",
    "    print(f\"   • Melhoria vs Baseline: {((best_strategy[1]['test_f1'] - baseline['test_f1']) / baseline['test_f1'] * 100):+.1f}%\")\n",
    "    \n",
    "    # Análise de agrupamento por threshold\n",
    "    threshold_groups = {}\n",
    "    for strategy, data in STRATEGIES_RESULTS.items():\n",
    "        threshold = data['optimal_threshold']\n",
    "        if threshold not in threshold_groups:\n",
    "            threshold_groups[threshold] = []\n",
    "        threshold_groups[threshold].append(strategy)\n",
    "    \n",
    "    print(f\"\\n Agrupamento por Threshold:\")\n",
    "    for threshold, strategies in sorted(threshold_groups.items()):\n",
    "        avg_f1 = np.mean([STRATEGIES_RESULTS[s]['test_f1'] for s in strategies])\n",
    "        print(f\"   • {threshold:.2f}: {', '.join(strategies)} (F1 médio: {avg_f1:.3f})\")\n",
    "    \n",
    "    return {\n",
    "        'f1_stats': {\n",
    "            'max': max(f1_scores),\n",
    "            'min': min(f1_scores),\n",
    "            'mean': np.mean(f1_scores),\n",
    "            'std': np.std(f1_scores)\n",
    "        },\n",
    "        'threshold_stats': {\n",
    "            'max': max(thresholds),\n",
    "            'min': min(thresholds),\n",
    "            'mean': np.mean(thresholds),\n",
    "            'std': np.std(thresholds)\n",
    "        },\n",
    "        'best_model': best_strategy,\n",
    "        'threshold_groups': threshold_groups\n",
    "    }\n",
    "\n",
    "def export_results():\n",
    "    \n",
    "    print(\"\\n Exportar Resultados...\")\n",
    "    \n",
    "    # Preparar dados para DataFrame\n",
    "    data = []\n",
    "    for strategy, results in STRATEGIES_RESULTS.items():\n",
    "        data.append({\n",
    "            'Estrategia': strategy,\n",
    "            'Validation_mAP': results['validation_map'],\n",
    "            'Test_F1': results['test_f1'],\n",
    "            'Test_Precision': results['test_precision'],\n",
    "            'Test_Recall': results['test_recall'],\n",
    "            'Optimal_Threshold': results['optimal_threshold'],\n",
    "            'Descricao': results['description']\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    df = df.sort_values('Test_F1', ascending=False)\n",
    "    \n",
    "    # Salvar CSV\n",
    "    output_file = \"resultados_thresholds_individuais.csv\"\n",
    "    df.to_csv(output_file, index=False, float_format='%.3f')\n",
    "    print(f\" Resultados salvos em: {output_file}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# 5. Função Principal\n",
    "\n",
    "def generate_plots(option='all'):    \n",
    "    \n",
    "    if option == 'all':\n",
    "        generate_dashboard()\n",
    "        generate_all_plots()\n",
    "        stats = analyze_results()\n",
    "        df = export_results()\n",
    "        print(\"\\n Dashboard + gráficos individuais + análise + export completos!\")\n",
    "        \n",
    "    elif option == 'dashboard':\n",
    "        generate_dashboard()\n",
    "        print(\"\\n Dashboard completo gerado!\")\n",
    "        \n",
    "    elif option == 'individual':\n",
    "        generate_all_plots()\n",
    "        print(\"\\n Todos os gráficos individuais gerados!\")\n",
    "        \n",
    "    elif option == 'analysis':\n",
    "        stats = analyze_results()\n",
    "        print(\"\\n Análise estatística concluída!\")\n",
    "        return stats\n",
    "        \n",
    "    elif option == 'export':\n",
    "        df = export_results()\n",
    "        print(\"\\n Resultados exportados!\")\n",
    "        return df\n",
    "    \n",
    "    print(f\"\\n Resumo dos Resultados:\")\n",
    "    best_model = max(STRATEGIES_RESULTS.items(), key=lambda x: x[1]['test_f1'])\n",
    "    baseline = STRATEGIES_RESULTS['Baseline']\n",
    "    \n",
    "    print(f\" Melhor estratégia: {best_model[0]}\")\n",
    "    print(f\" Test F1-Score: {best_model[1]['test_f1']:.3f}\")\n",
    "    print(f\" Threshold ótimo: {best_model[1]['optimal_threshold']:.2f}\")\n",
    "    print(f\" Melhoria vs baseline: {((best_model[1]['test_f1'] - baseline['test_f1']) / baseline['test_f1'] * 100):+.1f}%\")\n",
    "    print(f\" Range de thresholds: {min(OPTIMIZED_THRESHOLDS.values()):.2f} - {max(OPTIMIZED_THRESHOLDS.values()):.2f}\")    \n",
    "\n",
    "# 6. Execução e Instruções\n",
    "\n",
    "if __name__ == \"__main__\":   \n",
    "    \n",
    "    print(\"\\n Opções de Execução:\")\n",
    "    print(\"  generate_plots('all')        # Tudo: dashboard + individuais + análise + export\")\n",
    "    print(\"  generate_plots('dashboard')  # Apenas dashboard completo\")\n",
    "    print(\"  generate_plots('individual') # Apenas gráficos individuais\")\n",
    "    print(\"  generate_plots('analysis')   # Apenas análise estatística\")\n",
    "    print(\"  generate_plots('export')     # Apenas exportar CSV\")\n",
    "    print()\n",
    "    print(\" Gráficos Individuais:\")\n",
    "    print(\"  plot_ranking_final()           # Ranking final com thresholds\")\n",
    "    print(\"  plot_threshold_distribution()  # Distribuição dos thresholds\")\n",
    "    print(\"  plot_threshold_curves()        # Curvas de otimização\")\n",
    "    print(\"  plot_consistency_analysis()    # Análise de consistência\")\n",
    "    print()\n",
    "    print(\" Análises:\")\n",
    "    print(\"  analyze_results()              # Estatísticas detalhadas\")\n",
    "    print(\"  export_results()               # Exportar para CSV\") \n",
    "    \n",
    "# Executar automaticamente se desejar\n",
    "# generate_plots('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-25T04:18:19.216584Z",
     "iopub.status.busy": "2025-06-25T04:18:19.216048Z",
     "iopub.status.idle": "2025-06-25T04:18:21.412366Z",
     "shell.execute_reply": "2025-06-25T04:18:21.411767Z",
     "shell.execute_reply.started": "2025-06-25T04:18:19.216562Z"
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "generate_plots('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-25T04:20:35.049672Z",
     "iopub.status.busy": "2025-06-25T04:20:35.049361Z",
     "iopub.status.idle": "2025-06-25T04:20:35.056166Z",
     "shell.execute_reply": "2025-06-25T04:20:35.055429Z",
     "shell.execute_reply.started": "2025-06-25T04:20:35.049651Z"
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Bloco 9: Teste de Robustez - Inferência\n",
    "def quick_robustness_test():\n",
    "    \n",
    "    model_path = \"/kaggle/working/yolo_optimization/hyperparam_minimal_augmentation/weights/best.pt\"   \n",
    "    \n",
    "    test_seeds = [42, 123, 456, 789, 999]\n",
    "    results = []\n",
    "    \n",
    "    for i, seed in enumerate(test_seeds):\n",
    "        print(f\" Teste {i+1}/5 - Seed {seed}... \", end=\"\")\n",
    "        \n",
    "        set_seeds(seed)\n",
    "        model = YOLO(model_path)\n",
    "        val_results = model.val(\n",
    "            data=f\"{DATASET_PATH}/dataset.yaml\",\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        map50 = float(val_results.box.map50)\n",
    "        results.append(map50)\n",
    "        print(f\"mAP@0.5: {map50:.4f}\")\n",
    "    \n",
    "    # Análise\n",
    "    mean_map = np.mean(results)\n",
    "    std_map = np.std(results)\n",
    "    variability = (std_map / mean_map) * 100\n",
    "    \n",
    "    print(f\"\\n Análise:\")\n",
    "    print(f\"    Média: {mean_map:.4f}\")\n",
    "    print(f\"    Desvio: {std_map:.5f}\")\n",
    "    print(f\"    Variabilidade: {variability:.4f}%\")\n",
    "    \n",
    "    if variability < 0.01:\n",
    "        print(f\"    Excelente: Modelo totalmente determinístico\")\n",
    "    \n",
    "    return variability\n",
    "\n",
    "# Executar\n",
    "# variability = quick_robustness_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-25T04:20:44.210867Z",
     "iopub.status.busy": "2025-06-25T04:20:44.210586Z",
     "iopub.status.idle": "2025-06-25T04:21:15.882929Z",
     "shell.execute_reply": "2025-06-25T04:21:15.882073Z",
     "shell.execute_reply.started": "2025-06-25T04:20:44.210847Z"
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "variability = quick_robustness_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-25T04:40:26.900671Z",
     "iopub.status.busy": "2025-06-25T04:40:26.900372Z",
     "iopub.status.idle": "2025-06-25T04:40:26.912966Z",
     "shell.execute_reply": "2025-06-25T04:40:26.912356Z",
     "shell.execute_reply.started": "2025-06-25T04:40:26.900644Z"
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Bloco 10: Teste de Robustez - Treinamento com Múltiplas Seeds\n",
    "\n",
    "def test_training_robustness():      \n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    test_seeds = [42, 123, 456]  # 3 treinamentos independentes\n",
    "    results = []\n",
    "    \n",
    "    # Configurações Minimal Augmentation (suas configurações otimizadas)\n",
    "    training_config = {\n",
    "        'epochs': 50,        # Reduzido de 100 para economizar tempo\n",
    "        'batch': 16,\n",
    "        'patience': 15,\n",
    "        'lr0': 0.01,\n",
    "        'lrf': 0.1,\n",
    "        \n",
    "        # Minimal Augmentation específico\n",
    "        'mosaic': 0.5,       # Reduzido\n",
    "        'mixup': 0.0,        # Desabilitado\n",
    "        'copy_paste': 0.0,   # Desabilitado\n",
    "        'hsv_h': 0.01,       # Reduzido\n",
    "        'hsv_s': 0.3,        # Reduzido\n",
    "        'hsv_v': 0.2,        # Reduzido\n",
    "        'perspective': 0.0,  # Desabilitado\n",
    "    }\n",
    "    \n",
    "    for i, seed in enumerate(test_seeds):\n",
    "        print(f\"\\n Treinamento {i+1}/3 - Seed {seed}\")        \n",
    "        \n",
    "        set_seeds(seed)        \n",
    "        \n",
    "        model = YOLO('yolov8s.pt')\n",
    "        print(f\"    Modelo base carregado\")            \n",
    "        \n",
    "        # Treinamento\n",
    "        results_train = model.train(\n",
    "            data=f\"{DATASET_PATH}/dataset.yaml\",\n",
    "            project=f\"{OUTPUT_PATH}/robustness_training\",\n",
    "            name=f'minimal_aug_seed_{seed}',\n",
    "            seed=seed,\n",
    "            verbose=False,\n",
    "            plots=False,\n",
    "            **training_config\n",
    "        )\n",
    "        \n",
    "        # Avaliação\n",
    "        model_path = f\"{OUTPUT_PATH}/robustness_training/minimal_aug_seed_{seed}/weights/best.pt\"\n",
    "        \n",
    "        if Path(model_path).exists():\n",
    "            model_eval = YOLO(model_path)\n",
    "            val_results = model_eval.val(\n",
    "                data=f\"{DATASET_PATH}/dataset.yaml\",\n",
    "                verbose=False\n",
    "            )\n",
    "            \n",
    "            map50 = float(val_results.box.map50)\n",
    "            \n",
    "            results.append({\n",
    "                'seed': seed,\n",
    "                'map50': map50,\n",
    "                'success': True\n",
    "            })\n",
    "            \n",
    "            print(f\"    mAP@0.5: {map50:.3f}\")\n",
    "        else:\n",
    "            print(f\"    Modelo não salvo\")\n",
    "            results.append({'seed': seed, 'success': False})\n",
    "                \n",
    "        \n",
    "    \n",
    "    # Análise\n",
    "    successful = [r for r in results if r.get('success', False)]\n",
    "    \n",
    "    if len(successful) >= 2:\n",
    "        map50_values = [r['map50'] for r in successful]\n",
    "        mean_map = np.mean(map50_values)\n",
    "        std_map = np.std(map50_values)\n",
    "        variability = (std_map / mean_map) * 100\n",
    "        \n",
    "        print(f\"\\n Análise de Robustez:\")\n",
    "        print(f\"    mAP@0.5 médio: {mean_map:.3f}\")\n",
    "        print(f\"    Desvio padrão: {std_map:.4f}\")\n",
    "        print(f\"    Variabilidade: {variability:.2f}%\")\n",
    "        print(f\"    Range: {min(map50_values):.3f} - {max(map50_values):.3f}\")\n",
    "        \n",
    "        if variability < 1.0:\n",
    "            print(f\"    Excelente: Framework de treinamento robusto!\")\n",
    "        elif variability < 2.0:\n",
    "            print(f\"    Bom: Treinamento estável\")\n",
    "        else:\n",
    "            print(f\"    Atenção: Variabilidade alta\")\n",
    "        \n",
    "        elapsed = (time.time() - start_time) / 60\n",
    "        print(f\"\\n Tempo total: {elapsed:.1f} minutos\")\n",
    "        \n",
    "        # Para o texto\n",
    "        text_result = f\"variabilidade de {variability:.1f}% entre execuções independentes\"        \n",
    "        \n",
    "        return {\n",
    "            'variability': variability,\n",
    "            'mean': mean_map,\n",
    "            'std': std_map,\n",
    "            'text_result': text_result,\n",
    "            'results': successful\n",
    "        }\n",
    "    \n",
    "    return None\n",
    "\n",
    "print(\" Função definida - execute próxima célula\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-25T04:40:30.117909Z",
     "iopub.status.busy": "2025-06-25T04:40:30.117196Z"
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Executar teste de robustez do treinamento\n",
    "training_results = test_training_robustness()\n",
    "    \n",
    "if training_results:\n",
    "    print(f\"\\n TESTE CONCLUÍDO!\")\n",
    "    print(f\" Resultado: {training_results['text_result']}\")\n",
    "    \n",
    "    # Agora você tem AMBOS os resultados:\n",
    "    print(f\"\\n RESUMO COMPLETO:\")\n",
    "    print(f\"    Inferência: 0.0000% variabilidade (determinístico)\")\n",
    "    print(f\"    Treinamento: {training_results['variability']:.1f}% variabilidade\")\n",
    "else:\n",
    "    print(\" Teste falhou\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-25T05:07:09.131301Z",
     "iopub.status.busy": "2025-06-25T05:07:09.130988Z",
     "iopub.status.idle": "2025-06-25T05:07:09.171048Z",
     "shell.execute_reply": "2025-06-25T05:07:09.170241Z",
     "shell.execute_reply.started": "2025-06-25T05:07:09.131279Z"
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Bloco 11 - Análise Unificada - Detecção Automática Individual ou Batch\n",
    "# TCC: Função inteligente que detecta se é imagem única ou pasta para análise\n",
    "\n",
    "def load_optimized_model():   \n",
    "    \n",
    "    # Definindo modelo\n",
    "    model_path = \"/kaggle/working/yolo_optimization/hyperparam_minimal_augmentation/weights/best.pt\" #atenção para pasta que foi salva\n",
    "    model = YOLO(model_path)\n",
    "\n",
    "    return model\n",
    "    \n",
    "# Função Unificada Inteligente\n",
    "\n",
    "def smart_analysis(model, input_path, conf_threshold=0.45, max_visualize=6, save_reports=True):\n",
    "    \"\"\"    \n",
    "    Args:\n",
    "        model: Modelo YOLO carregado\n",
    "        input_path: Caminho para imagem ou pasta\n",
    "        conf_threshold: Threshold de confiança\n",
    "        max_visualize: Máximo de imagens para visualizar\n",
    "        save_reports: Se deve salvar relatórios    \n",
    "    \"\"\"\n",
    "    print(f\" Análise Iniciada\")    \n",
    "    \n",
    "    # Detectar tipo de input\n",
    "    input_path = Path(input_path)    \n",
    "    \n",
    "    # Verificar se é arquivo ou diretório\n",
    "    if input_path.is_file():\n",
    "        # É uma imagem única\n",
    "        print(f\"    Detectado: Imagem única\")\n",
    "        print(f\"    Arquivo: {input_path.name}\")\n",
    "        return _single_image_analysis(model, input_path, conf_threshold, save_reports)\n",
    "    \n",
    "    elif input_path.is_dir():\n",
    "        # É uma pasta (batch)\n",
    "        print(f\"    Detectado: Pasta para batch\")\n",
    "        print(f\"    Diretório: {input_path.name}\")\n",
    "        return _batch_analysis(model, input_path, conf_threshold, max_visualize, save_reports)\n",
    "    \n",
    "    else:\n",
    "        print(f\" ERRO: Tipo de input não reconhecido\")\n",
    "        return None\n",
    "\n",
    "def _single_image_analysis(model, image_path, conf_threshold, save_reports):\n",
    "    \n",
    "    print(f\"\\n Análise de Imagem Única\")    \n",
    "        \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # 1. Predição básica\n",
    "    print(f\"    Fazendo predição...\")\n",
    "    results = model(str(image_path), conf=conf_threshold, verbose=False)\n",
    "    \n",
    "    # 2. Extrair informações\n",
    "    detections = []\n",
    "    class_counts = {'COM_corante': 0, 'SEM_corante': 0}\n",
    "    confidences = {'COM_corante': [], 'SEM_corante': []}\n",
    "    \n",
    "    for result in results:\n",
    "        if result.boxes is not None:\n",
    "            boxes = result.boxes\n",
    "            \n",
    "            for i, box in enumerate(boxes):\n",
    "                conf = float(box.conf.cpu().numpy())\n",
    "                cls_id = int(box.cls.cpu().numpy())\n",
    "                class_name = model.names[cls_id]\n",
    "                bbox = box.xyxy.cpu().numpy()[0]\n",
    "                \n",
    "                detections.append({\n",
    "                    'id': i + 1,\n",
    "                    'class': class_name,\n",
    "                    'confidence': conf,\n",
    "                    'bbox': bbox\n",
    "                })\n",
    "                \n",
    "                class_counts[class_name] += 1\n",
    "                confidences[class_name].append(conf)\n",
    "    \n",
    "    inference_time = time.time() - start_time\n",
    "    total_cells = len(detections)\n",
    "    \n",
    "    # 3. Visualização\n",
    "    print(f\"    Gerando visualização...\")\n",
    "    _visualize_single_image(image_path, detections, class_counts)\n",
    "    \n",
    "    # 4. Estatísticas\n",
    "    print(f\"\\n    Resultados:\")\n",
    "    print(f\"      • Imagem: {image_path.name}\")\n",
    "    print(f\"      • Total de células: {total_cells}\")\n",
    "    if total_cells > 0:\n",
    "        print(f\"      • COM_corante: {class_counts['COM_corante']} ({class_counts['COM_corante']/total_cells*100:.1f}%)\")\n",
    "        print(f\"      • SEM_corante: {class_counts['SEM_corante']} ({class_counts['SEM_corante']/total_cells*100:.1f}%)\")\n",
    "    print(f\"      • Tempo de inferência: {inference_time:.3f}s\")\n",
    "    \n",
    "    # 5. Análise de confiança\n",
    "    if total_cells > 0:\n",
    "        print(f\"\\n    Análise de Confiança:\")\n",
    "        for class_name, confs in confidences.items():\n",
    "            if confs:\n",
    "                print(f\"      • {class_name}: {np.mean(confs):.3f} ± {np.std(confs):.3f}\")\n",
    "    \n",
    "    # 6. Relatório\n",
    "    if save_reports:\n",
    "        report = _generate_single_report(image_path, detections, class_counts, confidences, inference_time)\n",
    "        print(f\"    Relatório salvo\")\n",
    "    \n",
    "    return {\n",
    "        'type': 'single_image',\n",
    "        'image_path': str(image_path),\n",
    "        'detections': detections,\n",
    "        'class_counts': class_counts,\n",
    "        'confidences': confidences,\n",
    "        'total_cells': total_cells,\n",
    "        'inference_time': inference_time,\n",
    "        'report': report if save_reports else None\n",
    "    } \n",
    "    \n",
    "\n",
    "def _batch_analysis(model, folder_path, conf_threshold, max_visualize, save_reports):\n",
    "    \n",
    "    print(f\"\\n Análise de Batch\")    \n",
    "    \n",
    "    # Encontrar imagens\n",
    "    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']\n",
    "    image_files = []\n",
    "    \n",
    "    for file in folder_path.iterdir():\n",
    "        if file.suffix.lower() in image_extensions:\n",
    "            image_files.append(file)   \n",
    "    \n",
    "    print(f\"    Encontradas: {len(image_files)} imagens\")\n",
    "    print(f\"    Visualizando: {min(max_visualize, len(image_files))} primeiras\")\n",
    "    \n",
    "    # Processar todas as imagens\n",
    "    batch_results = []\n",
    "    all_detections = []\n",
    "    total_inference_time = 0\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for i, image_file in enumerate(image_files):\n",
    "        print(f\"    {i+1}/{len(image_files)}: {image_file.name}\")        \n",
    "        \n",
    "        # Predição individual\n",
    "        img_start = time.time()\n",
    "        results = model(str(image_file), conf=conf_threshold, verbose=False)\n",
    "        img_time = time.time() - img_start\n",
    "        total_inference_time += img_time\n",
    "        \n",
    "        # Processar resultados\n",
    "        image_result = {\n",
    "            'image_name': image_file.name,\n",
    "            'image_path': str(image_file),\n",
    "            'total_cells': 0,\n",
    "            'COM_corante': 0,\n",
    "            'SEM_corante': 0,\n",
    "            'confidences': {'COM_corante': [], 'SEM_corante': []},\n",
    "            'detections': [],\n",
    "            'inference_time': img_time\n",
    "        }\n",
    "        \n",
    "        for result in results:\n",
    "            if result.boxes is not None:\n",
    "                boxes = result.boxes\n",
    "                image_result['total_cells'] = len(boxes)\n",
    "                \n",
    "                for box in boxes:\n",
    "                    conf = float(box.conf.cpu().numpy())\n",
    "                    cls_id = int(box.cls.cpu().numpy())\n",
    "                    class_name = model.names[cls_id]\n",
    "                    bbox = box.xyxy.cpu().numpy()[0]\n",
    "                    \n",
    "                    image_result[class_name] += 1\n",
    "                    image_result['confidences'][class_name].append(conf)\n",
    "                    image_result['detections'].append({\n",
    "                        'class': class_name,\n",
    "                        'confidence': conf,\n",
    "                        'bbox': bbox\n",
    "                    })\n",
    "                    \n",
    "                    all_detections.append({\n",
    "                        'image': image_file.name,\n",
    "                        'class': class_name,\n",
    "                        'confidence': conf\n",
    "                    })\n",
    "        \n",
    "        batch_results.append(image_result)        \n",
    "        \n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    \n",
    "    # Consolidar estatísticas\n",
    "    total_images = len(batch_results)\n",
    "    total_cells = sum([img['total_cells'] for img in batch_results])\n",
    "    total_com = sum([img['COM_corante'] for img in batch_results])\n",
    "    total_sem = sum([img['SEM_corante'] for img in batch_results])\n",
    "    \n",
    "    print(f\"\\n    Resumo:\")\n",
    "    print(f\"      • Imagens processadas: {total_images}\")\n",
    "    print(f\"      • Total de células: {total_cells}\")\n",
    "    if total_cells > 0:\n",
    "        print(f\"      • COM_corante: {total_com} ({total_com/total_cells*100:.1f}%)\")\n",
    "        print(f\"      • SEM_corante: {total_sem} ({total_sem/total_cells*100:.1f}%)\")\n",
    "        print(f\"      • Média por imagem: {total_cells/total_images:.1f} células\")\n",
    "    print(f\"      • Tempo total: {total_time:.1f}s\")\n",
    "    print(f\"      • Velocidade: {total_images/total_time:.1f} imagens/segundo\")\n",
    "    \n",
    "    # Visualizações\n",
    "    print(f\"    Gerando visualizações...\")\n",
    "    _visualize_batch_sample(batch_results[:max_visualize])\n",
    "    _create_batch_statistics_plots(batch_results, all_detections)\n",
    "    \n",
    "    # Relatório\n",
    "    if save_reports:\n",
    "        report = _generate_batch_report(folder_path, batch_results, total_time)\n",
    "        print(f\"    Relatório batch salvo\")\n",
    "    \n",
    "    return {\n",
    "        'type': 'batch',\n",
    "        'folder_path': str(folder_path),\n",
    "        'batch_results': batch_results,\n",
    "        'all_detections': all_detections,\n",
    "        'consolidated_stats': {\n",
    "            'total_images': total_images,\n",
    "            'total_cells': total_cells,\n",
    "            'total_com': total_com,\n",
    "            'total_sem': total_sem,\n",
    "            'total_time': total_time,\n",
    "            'avg_cells_per_image': total_cells/total_images if total_images > 0 else 0\n",
    "        },\n",
    "        'report': report if save_reports else None\n",
    "    }\n",
    "\n",
    "# Funções de Visualização\n",
    "\n",
    "def _visualize_single_image(image_path, detections, class_counts):\n",
    "        \n",
    "    image = cv2.imread(str(image_path))\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "    \n",
    "    # Imagem original\n",
    "    axes[0].imshow(image_rgb)\n",
    "    axes[0].set_title('Imagem Original')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Imagem com detecções\n",
    "    annotated_image = image_rgb.copy()\n",
    "    colors = {'COM_corante': (0, 0, 255), 'SEM_corante': (255, 0, 0)}\n",
    "    \n",
    "    for det in detections:\n",
    "        bbox = det['bbox'].astype(int)\n",
    "        class_name = det['class']\n",
    "        conf = det['confidence']\n",
    "        color = colors[class_name]\n",
    "        \n",
    "        cv2.rectangle(annotated_image, (bbox[0], bbox[1]), (bbox[2], bbox[3]), color, 2)\n",
    "        cv2.putText(annotated_image, f'{class_name[:3]}: {conf:.2f}', \n",
    "                   (bbox[0], bbox[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "    \n",
    "    axes[1].imshow(annotated_image)\n",
    "    title = f'Detecções (Total: {len(detections)})\\n'\n",
    "    title += f'COM: {class_counts[\"COM_corante\"]}, SEM: {class_counts[\"SEM_corante\"]}'\n",
    "    axes[1].set_title(title)\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()       \n",
    "   \n",
    "\n",
    "def _visualize_batch_sample(sample_results):\n",
    "    \n",
    "    if not sample_results:\n",
    "        return\n",
    "    \n",
    "    n_samples = len(sample_results)\n",
    "    n_cols = min(3, n_samples)\n",
    "    n_rows = (n_samples + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5*n_rows))\n",
    "    if n_rows == 1:\n",
    "        axes = [axes] if n_cols == 1 else axes\n",
    "    else:\n",
    "        axes = axes.flatten()\n",
    "    \n",
    "    colors = {'COM_corante': 'blue', 'SEM_corante': 'red'}\n",
    "    \n",
    "    for i, img_result in enumerate(sample_results):\n",
    "        if i >= len(axes):\n",
    "            break        \n",
    "        \n",
    "        image = cv2.imread(img_result['image_path'])\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        axes[i].imshow(image_rgb)\n",
    "        \n",
    "        # Plotar detecções\n",
    "        for det in img_result['detections']:\n",
    "            bbox = det['bbox']\n",
    "            class_name = det['class']\n",
    "            \n",
    "            from matplotlib.patches import Rectangle\n",
    "            rect = Rectangle((bbox[0], bbox[1]), bbox[2]-bbox[0], bbox[3]-bbox[1],\n",
    "                           linewidth=2, edgecolor=colors[class_name], facecolor='none')\n",
    "            axes[i].add_patch(rect)\n",
    "        \n",
    "        title = f\"{img_result['image_name'][:15]}...\\n\"\n",
    "        title += f\"Total: {img_result['total_cells']}\"\n",
    "        axes[i].set_title(title, fontsize=10)\n",
    "        axes[i].axis('off')   \n",
    "        \n",
    "    # Ocultar axes extras\n",
    "    for i in range(len(sample_results), len(axes)):\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle('Amostra do Batch', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def _create_batch_statistics_plots(batch_results, all_detections):    \n",
    "    \n",
    "    df_images = pd.DataFrame(batch_results)\n",
    "    df_detections = pd.DataFrame(all_detections)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # 1. Células por imagem\n",
    "    axes[0,0].hist(df_images['total_cells'], bins=15, alpha=0.7, edgecolor='black')\n",
    "    axes[0,0].set_title('Distribuição de Células por Imagem')\n",
    "    axes[0,0].set_xlabel('Número de Células')\n",
    "    axes[0,0].set_ylabel('Frequência')\n",
    "    axes[0,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Proporção COM vs SEM\n",
    "    proportions = df_images['COM_corante'] / (df_images['COM_corante'] + df_images['SEM_corante'])\n",
    "    proportions = proportions.fillna(0)\n",
    "    \n",
    "    axes[0,1].hist(proportions, bins=10, alpha=0.7, edgecolor='black', color='orange')\n",
    "    axes[0,1].set_title('Proporção COM_corante por Imagem')\n",
    "    axes[0,1].set_xlabel('Proporção COM_corante')\n",
    "    axes[0,1].set_ylabel('Frequência')\n",
    "    axes[0,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Confiança por classe\n",
    "    if not df_detections.empty:\n",
    "        conf_com = df_detections[df_detections['class'] == 'COM_corante']['confidence']\n",
    "        conf_sem = df_detections[df_detections['class'] == 'SEM_corante']['confidence']\n",
    "        \n",
    "        if len(conf_com) > 0 and len(conf_sem) > 0:\n",
    "            axes[1,0].boxplot([conf_com, conf_sem], labels=['COM_corante', 'SEM_corante'])\n",
    "            axes[1,0].set_title('Confiança por Classe')\n",
    "            axes[1,0].set_ylabel('Confiança')\n",
    "            axes[1,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Correlação total vs COM\n",
    "    axes[1,1].scatter(df_images['total_cells'], df_images['COM_corante'], alpha=0.6)\n",
    "    axes[1,1].set_title('Total vs COM_corante')\n",
    "    axes[1,1].set_xlabel('Total de Células')\n",
    "    axes[1,1].set_ylabel('Células COM_corante')\n",
    "    axes[1,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Funções de Relatório\n",
    "\n",
    "def _generate_single_report(image_path, detections, class_counts, confidences, inference_time):\n",
    "    \n",
    "    report = f\"\"\"\n",
    "Relatório - Análise de Imagem Única\n",
    "Modelo Otimizado: 91.9% mAP@0.5\n",
    "\n",
    "Imagem: {image_path.name}\n",
    "Data/Hora: {time.strftime('%d/%m/%Y %H:%M:%S')}\n",
    "Threshold: 0.45\n",
    "\n",
    "Resultados:\n",
    "- Total: {len(detections)} células\n",
    "- COM_corante: {class_counts['COM_corante']} ({class_counts['COM_corante']/len(detections)*100:.1f}%)\n",
    "- SEM_corante: {class_counts['SEM_corante']} ({class_counts['SEM_corante']/len(detections)*100:.1f}%)\n",
    "- Tempo: {inference_time:.3f}s\n",
    "\n",
    "Detecções:\n",
    "\"\"\"\n",
    "    \n",
    "    for det in detections:\n",
    "        report += f\"- Célula {det['id']}: {det['class']} (conf: {det['confidence']:.3f})\\n\"\n",
    "    \n",
    "    filename = f\"relatorio_{image_path.stem}_{time.strftime('%Y%m%d_%H%M%S')}.txt\"\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(report)\n",
    "    \n",
    "    return report\n",
    "\n",
    "def _generate_batch_report(folder_path, batch_results, total_time):\n",
    "    \n",
    "    total_images = len(batch_results)\n",
    "    total_cells = sum([img['total_cells'] for img in batch_results])\n",
    "    total_com = sum([img['COM_corante'] for img in batch_results])\n",
    "    total_sem = sum([img['SEM_corante'] for img in batch_results])\n",
    "    \n",
    "    report = f\"\"\"\n",
    "Relatório - Análise em Lote\n",
    "Modelo Otimizado: 91.9% mAP@0.5\n",
    "\n",
    "Pasta: {folder_path.name}\n",
    "Data/Hora: {time.strftime('%d/%m/%Y %H:%M:%S')}\n",
    "Threshold: 0.45\n",
    "\n",
    "Resumo:\n",
    "- Imagens: {total_images}\n",
    "- Total células: {total_cells}\n",
    "- COM_corante: {total_com} ({total_com/total_cells*100:.1f}%)\n",
    "- SEM_corante: {total_sem} ({total_sem/total_cells*100:.1f}%)\n",
    "- Tempo: {total_time:.1f}s\n",
    "- Velocidade: {total_images/total_time:.1f} img/s\n",
    "\n",
    "Detalhes por Imagem:\n",
    "\"\"\"\n",
    "    \n",
    "    for img in batch_results:\n",
    "        report += f\"- {img['image_name']}: {img['total_cells']} células \"\n",
    "        report += f\"(COM: {img['COM_corante']}, SEM: {img['SEM_corante']})\\n\"\n",
    "    \n",
    "    filename = f\"relatorio_batch_{folder_path.name}_{time.strftime('%Y%m%d_%H%M%S')}.txt\"\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(report)\n",
    "    \n",
    "    return report\n",
    "\n",
    "# Função Principal Unificada\n",
    "\n",
    "def universal_analysis(input_path, conf_threshold=0.55, max_visualize=6, save_reports=True):\n",
    "    \n",
    "    # 1. Carregar modelo \n",
    "    model = load_optimized_model()\n",
    "    if model is None:\n",
    "        return None\n",
    "    \n",
    "    # 2. Análise inteligente\n",
    "    results = smart_analysis(model, input_path, conf_threshold, max_visualize, save_reports)\n",
    "    \n",
    "    if results:\n",
    "        print(f\"\\n Análise Concluída\")\n",
    "        print(f\"    Tipo: {results['type']}\")\n",
    "        if results['type'] == 'single_image':\n",
    "            print(f\"    Células detectadas: {results['total_cells']}\")\n",
    "        else:\n",
    "            print(f\"    Imagens processadas: {results['consolidated_stats']['total_images']}\")\n",
    "            print(f\"    Total de células: {results['consolidated_stats']['total_cells']}\")\n",
    "    \n",
    "    return results\n",
    "# Exemplos de Uso Atualizados\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Exemplos de Uso:\")\n",
    "    print()       \n",
    "    print(\"# 1. Imagem única\")\n",
    "    print(\"results = universal_analysis('/path/to/image.jpg')\")\n",
    "    print()\n",
    "    print(\"# 2. Pasta de imagens\")  \n",
    "    print(\"results = universal_analysis('/kaggle/working/yolo_dataset/images/test')\")\n",
    "    print()\n",
    "    print(\"# 3. Com parâmetros customizados\")\n",
    "    print(\"results = universal_analysis('/path/', conf_threshold=0.6, max_visualize=10)\")\n",
    "    print()\n",
    "    print(\" Detecta automaticamente o tipo de input\")\n",
    "    print(\" Gera visualizações e relatórios apropriados\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-06-25T05:09:09.929451Z",
     "iopub.status.busy": "2025-06-25T05:09:09.928926Z",
     "iopub.status.idle": "2025-06-25T05:09:18.932701Z",
     "shell.execute_reply": "2025-06-25T05:09:18.931950Z",
     "shell.execute_reply.started": "2025-06-25T05:09:09.929428Z"
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "results = universal_analysis('/kaggle/working/yolo_dataset/images/test/', conf_threshold=0.45, max_visualize=32)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7663772,
     "sourceId": 12168055,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
